{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying all the imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool, tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from dotenv import load_dotenv\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser, ListOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "import re\n",
    "import os\n",
    "\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    utility,\n",
    ")\n",
    "from vector_database_rawtxt import create_milvus_db\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "def get_numbers(query: str):\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0)\n",
    "    template = \"\"\"\n",
    "    You are smart agent that can idenify all the client ids to solve the query. \n",
    "    If no start point for a client is mentioned, assume client 1 is the first client.\n",
    "    id. From the query, return all the ids that the query refers to as a list of integers.\n",
    "    {format_instructions}\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    class Numbers(BaseModel):\n",
    "        numbers: str = Field(description=\"should say 'the numbers extracted from the query'\")\n",
    "        relevant_numbers: list = Field(description=\"should be a list of all the relevant numbers the llm has picked up\")\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=Numbers)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = ['query'],\n",
    "        template=template,\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "    ans = chain.invoke(query)\n",
    "    return ans['relevant_numbers']\n",
    "        \n",
    "\n",
    "@tool\n",
    "def search_tool(query : str):\n",
    "    \"\"\" \n",
    "    Takes a user query and performs an online search to provide\n",
    "    an answer to that query.\n",
    "    \"\"\"\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    answer = search.run(query)\n",
    "    return answer\n",
    "\n",
    "@tool\n",
    "def query_embeddings(query : str):\n",
    "    \"\"\"\n",
    "    Loads in a vector store to give precise information about recent company financial information taken from their \n",
    "    10-k reports. \n",
    "    A similarity search is performed from your query on these reports and relevant information is returned to you.\n",
    "    \"\"\"\n",
    "    from vector_database_rawtxt import create_milvus_db\n",
    "    vector_store = create_milvus_db()\n",
    "    vector_store.load()\n",
    "\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embedded_query_qn = model.encode(query)\n",
    "\n",
    "    search_params = {\n",
    "    \"metric_type\": \"L2\"\n",
    "    }\n",
    "\n",
    "    result = vector_store.search(\n",
    "        [embedded_query_qn.tolist()], # a single query must still be enclosed in a list\n",
    "        \"embedding\",\n",
    "        search_params,\n",
    "        limit=5\n",
    "    )\n",
    "\n",
    "    chunk_list = []\n",
    "    res = []\n",
    "    for hit in result:\n",
    "        for id in hit:\n",
    "            chunk_list.append(id.id)\n",
    "\n",
    "    for id in chunk_list:\n",
    "        search_result = vector_store.query(expr=f\"pk == {id}\", output_fields=[\"*\"])\n",
    "        res.append(search_result[0][\"plain_text\"])\n",
    "    return res\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_database(query : str):\n",
    "    \"\"\"\n",
    "    This function queries the SQL database based on the query that the user inputs.\n",
    "    This will provide insight into the current client(s) stock portfolio from the portfolio table in the database.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0)\n",
    "    db = SQLDatabase.from_uri('sqlite:///portfolio_allocations.db')\n",
    "    agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)\n",
    "    result = agent_executor.invoke(query)\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    client = get_numbers(query)\n",
    "    for i in client:\n",
    "        response_schemas = [\n",
    "        ResponseSchema(name=f'Client {i}', description=f\"A dictionary containing the stock tickers and their percentage allocations for each client {i}.\")\n",
    "        ]\n",
    "      \n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    template=\"create a new key, value pair for every client mentioned in the question.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    ans = chain.invoke({\"question\": result})\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def portfolio_allocation(query : str):\n",
    "    \"\"\"\n",
    "    Based on the allocation stratergy provided as a query, context on the comapany's recent financials from their 10-k reports\n",
    "    and their up-to-date status from an online search, change the allocation in the\n",
    "    client stock portfolios in the SQL database.\n",
    "    \"\"\"\n",
    " \n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant who is going to allocate different weights based on context and the invest stratergy that user wants.\n",
    "    In order to retreieve the context, use the search_tool and the query_embedding tool to search 'Tell me about the fininical siutuation of\n",
    "    AAPL, MSFT, NVIDIA'. Combining this with the allocation stratergy that the user picks, redistribute the allocation percentages. Give exact figures \n",
    "    as to how this is to be used for each stock. You should also give a detailed explanation as to why you came up with these figures. Use the context\n",
    "    to provide statistics in order to boost your reasoning. Make sure the reasoning is also returned in the final answwer.\n",
    "\n",
    "    Query : {query}\n",
    "    {answer}\n",
    "    \"\"\"\n",
    "   \n",
    "    examples = [\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a balanced strategy',\n",
    "        'answer': 'The stock allocations for client_id 1 equal across all stocks, totalling 100.'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a risk-based strategy',\n",
    "        'answer': \"\"\"\n",
    "                        Allocating more to stocks with lower perceived risk. \n",
    "                        From my 10k data and online search, Company 1 has strong financials\n",
    "                        and minimal risk but Comapany 2 has more risk. As a result, the stock\n",
    "                        allocation fror client_id 1 would have a higher percentage for Company 1\n",
    "                        and a lower percentage for Company 2. Company 3 would make up the rest of the portfolio.\n",
    "                        \"\"\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a return-based strategy',\n",
    "        'answer' : \"\"\"\n",
    "                        Allocating more to stocks with higher expected returns.\n",
    "                        From my 10k data and online search, Company 3 has higher expected growth rates and returns\n",
    "                        whereas Company 2 has a declining industry position and poor management quality. As a result, the stock\n",
    "                        allocation fror client_id 1 would have a high percentage for Company 3\n",
    "                        and a low percentage for Company 2 and Company 1 would make up the rest of the portfolio.\n",
    "                        \"\"\"\n",
    "    }\n",
    "    ]\n",
    "    c1 = query_embeddings(\"what is the current financial outlook of AAPL, MSFT, NVIDIA\")\n",
    "    c2 = search_tool(\"what is the current financial outlook of AAPL, MSFT, NVIDIA\")\n",
    "\n",
    "    context = c1.append(c2)\n",
    "\n",
    "    example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"], template=template\n",
    "    )\n",
    "\n",
    "    prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Query: {input}, Context: {context}\",\n",
    "    input_variables=[\"input\", \"context\"],\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "\n",
    "    chain = prompt | llm\n",
    "\n",
    "    #print(f\"context: {context}\")\n",
    "    ans = chain.invoke({'input' : query, 'context':context})\n",
    "    \n",
    "    query_database(f\"set the stock allocations for the client and percentages from {ans.content} provide the sql query to do so and execute it on the database\")\n",
    "    \n",
    "    return ans.content\n",
    "\n",
    "    \n",
    "# tools = [Tool(name=\"search_tool\", func=search_tool, description=\"Tool for performing online search operations\"),\n",
    "#          Tool(name=\"query_embeddings\", func=query_embeddings, description=\"Tool for performing vector similarity search on comapny financial data from their 10-K reports.\"),\n",
    "#          Tool(name='query_database', func=query_database, description= \"This function queries the SQL database based on the query that the user provides to provide insight into the current client stock portfolio\"),\n",
    "#          Tool(name='portfolio_allocation', func=portfolio_allocation, description='This function uses context from the vector database and online searches as well as the investment stratergy the user specifies to determine the stock allocation splits')]\n",
    "tools = [\n",
    "         Tool(name=\"query_embeddings\", func=query_embeddings, description=\"Tool for performing vector similarity search on comapny financial data from their 10-K reports.\"),\n",
    "         Tool(name=\"search_tool\", func=search_tool, description=\"Tool for performing online search operations\"),\n",
    "         Tool(name='query_database', func=query_database, description= \"This function queries the SQL database based on the query that the user provides to provide insight into the current client stock portfolio\"),\n",
    "         Tool(name='portfolio_allocation', func=portfolio_allocation, description='This function uses context from the vector database and online searches as well as the investment stratergy the user specifies to determine the stock allocation splits')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the portfolio_allocation tool for this query since it involves a specific client and a strategy.\n",
      "\n",
      "Action: portfolio_allocation\n",
      "\n",
      "Action Input:\n",
      "{\n",
      "  \"client_id\": 1,\n",
      "  \"strategy\": \"risk-based\"\n",
      "}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GenAIProject\\GenAIGroupProject\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain text and embeddings have been successfully loaded from data/annual_filings_model_state.pkl\n",
      "Index, plain text and embeddings have been successfully inserted into your Milvus Collection\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mportfolio\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'portfolio'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE portfolio (\n",
      "\t\"ClientId\" INTEGER, \n",
      "\t\"AAPL\" DECIMAL(2, 2) NOT NULL, \n",
      "\t\"MSFT\" DECIMAL(2, 2), \n",
      "\t\"NVIDIA\" DECIMAL(2, 2), \n",
      "\tPRIMARY KEY (\"ClientId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from portfolio table:\n",
      "ClientId\tAAPL\tMSFT\tNVIDIA\n",
      "1\t0.30\t0.40\t0.30\n",
      "2\t0.40\t0.30\t0.30\n",
      "3\t0.33\t0.33\t0.33\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'UPDATE portfolio\\nSET AAPL = 0.40,\\n    MSFT = 0.30,\\n    NVIDIA = 0.30\\nWHERE ClientId = 1;'}`\n",
      "responded: The `portfolio` table contains the stock allocations for different clients. Each row represents a client with their allocations for AAPL, MSFT, and NVIDIA.\n",
      "\n",
      "To update the stock allocations for client 1 based on the risk-based strategy provided, I will execute the following SQL query:\n",
      "\n",
      "```sql\n",
      "UPDATE portfolio\n",
      "SET AAPL = 0.40,\n",
      "    MSFT = 0.30,\n",
      "    NVIDIA = 0.30\n",
      "WHERE ClientId = 1;\n",
      "```\n",
      "\n",
      "I will now run this query to update the stock allocations for client 1.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe stock allocations for client 1 have been successfully updated based on the risk-based strategy provided.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mBased on a risk-based strategy for client 1, the stock allocation would be as follows:\n",
      "\n",
      "- AAPL: 40%\n",
      "- MSFT: 30%\n",
      "- NVIDIA: 30%\n",
      "\n",
      "This allocation is based on the perceived risk levels of each company. From the financial situation analysis, AAPL has strong financials and minimal risk, making it a safer investment option. Therefore, it receives the highest allocation of 40%. MSFT is considered to have moderate risk, so it receives a 30% allocation. NVIDIA, with potentially higher risk factors, receives a 30% allocation to balance out the portfolio.\n",
      "\n",
      "This allocation aims to minimize risk exposure for client 1 while still maintaining a diversified portfolio across different companies.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "\n",
      "Final Answer: The stock allocation for client 1 using a risk-based strategy is as follows:\n",
      "- AAPL: 40%\n",
      "- MSFT: 30%\n",
      "- NVIDIA: 30%\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The stock allocation for client 1 using a risk-based strategy is as follows:\n",
      "- AAPL: 40%\n",
      "- MSFT: 30%\n",
      "- NVIDIA: 30%\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "Only use the portfolio_allocation tool if the terms 'strategy' AND 'client' are provided in the query.\n",
    "Otherwise any queries involving 'client' you should only use the query_database tool. \n",
    "\n",
    "If the user query requests information which doesn't require the need for a SQL database, use the query_emebddings tool.\n",
    "Only use the search_tool tool if there query involves things the query_embeddings tools does not provide an output. \n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "If your thought before the final answer includes the output from the portfolio_allocation tool, give the response by including ACTUAL percentages totalling to 100. \n",
    "\n",
    "Final Answer: the final answer to the ORIGINAL input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the query and create the prompt\n",
    "#query = 'return the values for client_id 1 in the sql database and also tell me the current apple stock price'\n",
    "\n",
    "#sql queries\n",
    "#query = 'Return me the stock allocation for client 5'\n",
    "#query = 'Return me the stock allocation for client 8'\n",
    "#query = 'Return me the stock allocation for every client'\n",
    "#query = 'give me all the stock allocations from all clients up to client 3'\n",
    "#query = 'give me all the stock allocations from all clients up to client 3'\n",
    "#query = 'give me all the stock allocations for client 8'\n",
    "#query = \"The Company continues to develop new technologies to enhance existing products and services and to expand the range of its offerings through research and development RD licensing of intellectual property and acquisition of thirdparty businesses and technology\"\n",
    "\n",
    "#portfolio allocation queries \n",
    "#query = \"How much Profit did company Apple make in comparison to Microsoft in 2021?\"\n",
    "#query =  \"add a new client to the database with random stock allocations, provide the sql query to do so and execute it\"\n",
    "#query =  \"set the stock allocations for client_id 1 to 5,5,90. provide the sql query to do so and execute it on the database\" #remeber to pull numbers from another query into this framework\n",
    "query = 'Reallocate the stocks for client 1 using a risk-based stratergy'\n",
    "\n",
    "#search queries\n",
    "#query = 'Tell me the todays MSFT stock price'\n",
    "\n",
    "#embedding queries\n",
    "#query = \"What are the strategic objectives of Apple over in 2023?\"\n",
    "#query = \"Give me a sentence from the apple 10-k report\"\n",
    "#query = \"Give me the net sale value for iphones in 2022\"\n",
    "#query = \"Give me the net sales for Nvidia in Q4 2021\"\n",
    "#query = \"What is the general sentiment about apple based on the 2022 report?\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['input','tools', 'agent_scratchpad', 'tool_names'], template=template)\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "\n",
    "\n",
    "# Create the agent using the language model and the toolset\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# Execute the agent with the given input\n",
    "response = agent_executor.invoke({'input': query, 'tools' : tools, 'tool_names' : [tool.name for tool in tools]})\n",
    "\n",
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
