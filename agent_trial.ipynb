{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying all the imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool, tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from dotenv import load_dotenv\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "import re\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dotenv and specifying tools\n",
    "load_dotenv()\n",
    "\n",
    "def extract_clients(query: str) -> list:\n",
    "    num_list = []\n",
    "    if 'all clients' in query:\n",
    "        for i in range(1,11):\n",
    "            num_list.append(i)\n",
    "    else:\n",
    "        for i in query:\n",
    "            if i.isdigit():\n",
    "                num_list.append(int(i))\n",
    "    return num_list\n",
    "\n",
    "        \n",
    "\n",
    "@tool\n",
    "def search_tool(query : str):\n",
    "    \"\"\" \n",
    "    Takes a user query and performs an online search to provide\n",
    "    an answer to the query\n",
    "    \"\"\"\n",
    "    \n",
    "    search = DuckDuckGoSearchRun()\n",
    "    answer = search.run(query)\n",
    "    return answer\n",
    "\n",
    "@tool\n",
    "def create_embeddings(query : str):\n",
    "    \"\"\"\n",
    "    Uses the content from the file path to create embeddings on the inputted data. Using the query\n",
    "    provided, perform a similarity search on the query and return the output. If you can not provide a response,\n",
    "    say I don't know rather than providing an incorrect response.\n",
    "    \"\"\"\n",
    "\n",
    "    #file_path = r'C:\\GenAI\\Final Project\\GenAIGroupProject\\apple.txt'\n",
    "    file_path = r'./apple.txt'\n",
    "    file_path = file_path.strip()\n",
    "    loader = TextLoader(file_path, encoding= 'utf-8')\n",
    "    document = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunk = text_splitter.split_documents(documents=document)\n",
    "    embeddings = OpenAIEmbeddings(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    vectorstore = FAISS.from_documents(chunk, embeddings)\n",
    "\n",
    "    docs = vectorstore.similarity_search(query)\n",
    "    return docs[0].page_content\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_database(query : str):\n",
    "    \"\"\"\n",
    "    This function queries the SQL database based on the query that the user provides\n",
    "    to provide insight into the current client stock portfolio\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    # Initialize the JSON output key parser\n",
    "\n",
    "\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0)\n",
    "    db = SQLDatabase.from_uri('sqlite:///portfolio_allocations.db')\n",
    "    agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)\n",
    "    result = agent_executor.invoke(query)\n",
    "\n",
    "    \n",
    "    clients = [f\"client{i}\" for i in extract_clients(query)]\n",
    "\n",
    "    # Define the response schemas dynamically based on the number of clients\n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=client, description=f\"A dictionary containing stock tickers and their percentage allocations for {client}.\")\n",
    "        for client in clients\n",
    "    ]\n",
    "\n",
    "    # Initialize the structured output parser\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "    # Get the format instructions\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    # Define the prompt template\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=\"Create a new key, value pair for every new client mentioned in the question.\\n{format_instructions}\\nQuestion: {question}\",\n",
    "        input_variables=[\"question\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "    )\n",
    "\n",
    "    \n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    template=\"create a new key, value pair for every new client mentioned in the question.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "    \n",
    "    \n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    ans = chain.invoke({\"question\": result})\n",
    "\n",
    "    return ans\n",
    "\n",
    "    \n",
    "@tool\n",
    "def portfolio_allocation(query : str):\n",
    "    \"\"\"\n",
    "    Based on the allocation stratergy provided as a query, change the allocation in the\n",
    "    client stock portfolio in the SQL database\n",
    "    \"\"\"\n",
    "    #query = Reallocte the portfolio for client 1 with a balanced strategy\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "    examples = [\n",
    "        {\n",
    "            'query' : 'Reallocte the portfolio for client 1 with a balanced strategy',\n",
    "            'answer' : ' The stock allocations for client_id 1 to 33,33,33'\n",
    "        },\n",
    "\n",
    "        {\n",
    "            'query' : 'Reallocte the portfolio for client 1 with a risk-based strategy',\n",
    "            'answer' : \"\"\"\n",
    "                        Allocating more to stocks with lower perceived risk. \n",
    "                        From my 10k data and online search, AAPL has strong financialas\n",
    "                        and minimal risk but NVIDIA has more risk. As a result, the stock\n",
    "                        allocation fror client_id 1 would have a high percentage for AAPL\n",
    "                        and a low percentage for NVIDIA.\n",
    "                        \"\"\"\n",
    "        },\n",
    "\n",
    "        {\n",
    "            'query': 'Reallocte the portfolio for client 1 with a return-based strategy',\n",
    "            'answer' : \"\"\"\n",
    "                        Allocating more to stocks with higher expected returns.\n",
    "                        From my 10k data and online search, NVIDIA has higher expected growth rates and returns\n",
    "                        whereas MSFT has a declining industry position and poor management quality. As a result, the stock\n",
    "                        allocation fror client_id 1 would have a high percentage for NVIDIA\n",
    "                        and a low percentage for MSFT\n",
    "                        \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ten_k_data = create_embeddings('Summarize the current financial situation of AAPL, MSFT & NVIDIA')\n",
    "    online_search = search_tool('Summarize the current financial situation of AAPL, MSFT & NVIDIA')\n",
    "\n",
    "    example_template = \"\"\"\n",
    "    User: {query}\n",
    "    AI: {answer}\n",
    "    \"\"\"\n",
    "\n",
    "    example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    "    )\n",
    "\n",
    "    prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "    assistant. The assistant uses the context provided from the 10k and online search to gather information\n",
    "    about the company's financial situation using the create_embeddings and search_tool.\n",
    "    to make informed decisions based on the investment strategy in the user query.\n",
    "    The assistant then reallocated the user's stock portfolio. This should be done only\n",
    "    for AAPL, MSFT, NVIDIA.\n",
    "    \"\"\"\n",
    "\n",
    "    suffix = \"\"\"\n",
    "    User: {query}\n",
    "    AI: \n",
    "    \"\"\"\n",
    "\n",
    "    few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    "    )\n",
    "\n",
    "    chain = few_shot_prompt_template | llm\n",
    "\n",
    "    ans = chain.invoke(query)\n",
    "    return ans\n",
    "\n",
    "       \n",
    "\n",
    "    #  1. Read in the client database using the query database tool\n",
    "    #  = f\"Return the values of the stock holdings for client_id {query} in the sql database\"\n",
    "    #query_database(s1_query)\n",
    "    \n",
    "    #  2. Determine allocation stratergy based on query\n",
    "    \n",
    "    \n",
    "\n",
    "    #  3. Read in the Financials from the 10k\n",
    "\n",
    "    #  4. Get current information from online\n",
    "\n",
    "    #  5. Apply the stratergy we determined on the information from steps 3 and 4!\n",
    "\n",
    "    #  6. Translate this into a percentage allocation for each company and write to database\n",
    "\n",
    "    #  7. Update database based on new percentages\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "tools = [Tool(name=\"search_tool\", func=search_tool, description=\"Tool for performing online search operations\"),\n",
    "         Tool(name=\"create_embeddings\", func=create_embeddings, description=\"Uses the content from the file path to create embeddings on the inputted data. Using the query provided, perform a similarity search on the query and return the output. If you can not provide a response,say I don't know rather than providing an incorrect response.\"),\n",
    "        Tool(name='query_database', func=query_database, description= \"This function queries the SQL database based on the query that the user provides to provide insight into the current client stock portfolio\"),\n",
    "        Tool(name='portfolio_allocation', func=portfolio_allocation, description = 'This function rellocated stocks for the specified clients based on context and their investment stratergy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the portfolio_allocation tool to reallocate the portfolio for client 6 based on a return-based strategy.\n",
      "\n",
      "Action: portfolio_allocation\n",
      "\n",
      "Action Input: \n",
      "{\n",
      "  \"client_id\": 6,\n",
      "  \"strategy\": \"return-based\"\n",
      "}\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mcontent='Allocating more to stocks with higher expected returns.\\nFrom my 10k data and online search, NVIDIA has higher expected growth rates and returns\\nwhereas MSFT has a declining industry position and poor management quality. As a result, the stock\\nallocation for client_id 6 would have a high percentage for NVIDIA\\nand a low percentage for MSFT.' response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 362, 'total_tokens': 434}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4bc63fb4-4c78-41fd-bf72-bdbe8a4add5a-0'\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: {\n",
      "    \"client_id\": 6,\n",
      "    \"strategy\": \"return-based\",\n",
      "    \"allocation\": {\n",
      "        \"NVIDIA\": 70,\n",
      "        \"MSFT\": 30\n",
      "    }\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"client_id\": 6,\n",
      "    \"strategy\": \"return-based\",\n",
      "    \"allocation\": {\n",
      "        \"NVIDIA\": 70,\n",
      "        \"MSFT\": 30\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You need to use the tools to find the appropriate action to take. \n",
    "Only use the query_database and portfolio_allocation tools when the term \"clients\" is mentioned in the query.\n",
    "If further queries are presented alongside the term \"clients\", then use all tools available.\n",
    "Otherwise, ignore these two tools and use the embeddings first\n",
    "to see if you can get relevant responses from the similarity search from the user's query. If you do get relevant\n",
    "responses, please return the responses from the similarity search. If you can't get relevent results from the embeddings,\n",
    "use the seatch tool and get the reponse from there. If you still can't find an answer from an online search, please do not make up an\n",
    "answer and return 'Sorry I can not answer your query' instead.\n",
    "\n",
    "If performing portfolio_allocation, get context of the company's financial situation by using the create_embeddings and search tool by querying:\n",
    "\"Tell me about the company's financial situation\" and make the percentage splits based on this and the investment stratergy. This should be done only\n",
    "for AAPL, MSFT, NVIDIA. Give the response by including actual percentages rather than 'higher' or 'lower' percentage.\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "If only the query_database is used, return  what is in the function as a dictionary as the final answer. It\n",
    "shoudl be in this format:\n",
    "\n",
    "\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Define the query and create the prompt\n",
    "#query = 'return the values for client_id 1 in the sql database and also tell me the current apple stock price'\n",
    "#query = 'Tell me the current apple stock price'\n",
    "query = 'Reallocte the portfolio for client 6 with a return-based strategy'\n",
    "#query = \"The Company continues to develop new technologies to enhance existing products and services and to expand the range of its offerings through research and development RD licensing of intellectual property and acquisition of thirdparty businesses and technology\"\n",
    "#query = \"Give me a sentence from the apple 10-k report\"\n",
    "#query = \"what is the net sales of Macs in 2021\"\n",
    "#query =  \"add a new client to the database with random stock allocations, provide the sql query to do so and execute it\"\n",
    "#query =  \"set the stock allocations for client_id 1 to 5,5,90. provide the sql query to do so and execute it on the database\" #remeber to pull numbers from another query into this framework\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['input','tools', 'agent_scratchpad', 'tool_names'], template=template)\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "\n",
    "# Create the agent using the language model and the toolset\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=False)\n",
    "\n",
    "# Execute the agent with the given input\n",
    "response = agent_executor.invoke({'input': query, 'tools' : tools, 'tool_names' : [tool.name for tool in tools]})\n",
    "\n",
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
