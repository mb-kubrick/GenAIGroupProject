{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying all the imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool, tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dotenv and specifying tools\n",
    "load_dotenv()\n",
    "\n",
    "@tool\n",
    "def search_tool(query : str):\n",
    "    \"\"\" \n",
    "    Takes a user query and performs an online search to provide\n",
    "    an answer to the query\n",
    "    \"\"\"\n",
    "    \n",
    "    search = DuckDuckGoSearchRun()\n",
    "    answer = search.run(query)\n",
    "    return answer\n",
    "\n",
    "@tool\n",
    "def create_embeddings(query : str):\n",
    "    \"\"\"\n",
    "    Uses the content from the file path to create embeddings on the inputted data. Using the query\n",
    "    provided, perform a similarity search on the query and return the output. If you can not provide a response,\n",
    "    say I don't know rather than providing an incorrect response.\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = r'C:\\GenAI\\Final Project\\GenAIGroupProject\\apple.txt'\n",
    "    file_path = file_path.strip()\n",
    "    loader = TextLoader(file_path, encoding= 'utf-8')\n",
    "    document = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunk = text_splitter.split_documents(documents=document)\n",
    "    embeddings = OpenAIEmbeddings(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    vectorstore = FAISS.from_documents(chunk, embeddings)\n",
    "\n",
    "    docs = vectorstore.similarity_search(query)\n",
    "    return docs[0].page_content\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_database(query : str):\n",
    "    \"\"\"\n",
    "    This function queries the SQL database based on the query that the user provides\n",
    "    to provide insight into the current client stock portfolio\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "    db = SQLDatabase.from_uri('')\n",
    "    agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)\n",
    "    ans = agent_executor.invoke(query)\n",
    "    return ans\n",
    "\n",
    "@tool\n",
    "def portfolio_allocation(query : str):\n",
    "    \"\"\"\n",
    "    Based on the allocation stratergy provided as a query, change the allocation in the\n",
    "    client stock portfolio in the SQL database\n",
    "    \"\"\"\n",
    "    #  1. Read in the client database using thhe query database tool\n",
    "    \n",
    "    #  2. Determine allocation stratergy based on query\n",
    "\n",
    "    #  3. Read in the Financials from the 10k\n",
    "\n",
    "    #  4. Get current information from online\n",
    "\n",
    "    #  5. Apply the stratergy we determined on the information from steps 3 and 4\n",
    "\n",
    "    #  6. Translate this into a percentage allocation for each company and write to database\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "tools = [Tool(name=\"search_tool\", func=search_tool, description=\"Tool for performing online search operations\"),\n",
    "         Tool(name=\"create_embeddings\", func=create_embeddings, description=\"Uses the content from the file path to create embeddings on the inputted data. Using the query provided, perform a similarity search on the query and return the output. If you can not provide a response,say I don't know rather than providing an incorrect response.\")]\n",
    "        #  Tool(name='query_database', func=query_database, description= \"This function queries the SQL database based on the query that the user provides to provide insight into the current client stock portfolio\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should start by using the create_embeddings tool to see if I can find any relevant responses from the embeddings.\n",
      "\n",
      "Action: create_embeddings\n",
      "\n",
      "Action Input: file path to create embeddings, query: \"sadfidsagigsadifgoidsagfoisagdfidsa\"\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mr20210926202209240000320193aaplWearablesHomeandAccessoriesMember20200927202109250000320193aaplWearablesHomeandAccessoriesMember201909292020092600003201932022092520220924xbrlipure0000320193202310012022092400003201932024092920220924000032019320250928202209240000320193usgaapCashMember202209240000320193usgaapMoneyMarketFundsMemberusgaapFairValueInputsLevel1Member202209240000320193usgaapMutualFundMemberusgaapFairValueInputsLevel1Member202209240000320193usgaapFairValueInputsLevel1Member202209240000320193usgaapUSTreasurySecuritiesMemberusgaapFairValueInputsLevel2Member202209240000320193usgaapFairValueInputsLevel2MemberusgaapUSGovernmentAgenciesDebtSecuritiesMember202209240000320193usgaapForeignGovernmentDebtSecuritiesMemberusgaapFairValueInputsLevel2Member202209240000320193usgaapFairValueInputsLevel2MemberusgaapBankTimeDepositsMember202209240000320193usgaapFairValueInputsLevel2MemberusgaapCommercialPaperMember202209240000320193usgaapCorporateDebtSecuritiesMemberusgaapFairValueInputsLevel2Memb\u001b[0m\u001b[32;1m\u001b[1;3mI found some results from the embeddings, but they seem to be unrelated to the query. I should try using the search_tool to see if I can find a relevant answer.\n",
      "\n",
      "Action: search_tool\n",
      "\n",
      "Action Input: query: \"sadfidsagigsadifgoidsagfoisagdfidsa\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo good DuckDuckGo Search Result was found\u001b[0m\u001b[32;1m\u001b[1;3mI couldn't find any relevant information from the embeddings or the online search. I should return 'Sorry I can not answer your query' as I don't have any relevant information to provide.\n",
      "\n",
      "Final Answer: Sorry I can not answer your query\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Sorry I can not answer your query\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You need to use the tools to find the appropriate action to take. Use the embeddings first\n",
    "to see if you can get relevant responses from the similarity search from the user's query. If you do get relevant\n",
    "responses, please return the responses from the similarity search. If you can't get relevent results from the embeddings,\n",
    "use the seatch tool and get the reponse from there. If you still can't find an answer from an online search, please do not make up an\n",
    "answer and return 'Sorry I can not answer your query' instead.\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Define the query and create the prompt\n",
    "query = 'sadfidsagigsadifgoidsagfoisagdfidsa'\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['input','tools', 'agent_scratchpad', 'tool_names'], template=template)\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "\n",
    "\n",
    "# Create the agent using the language model and the toolset\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# Execute the agent with the given input\n",
    "response = agent_executor.invoke({'input': query, 'tools' : tools, 'tool_names' : [tool.name for tool in tools]})\n",
    "\n",
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
