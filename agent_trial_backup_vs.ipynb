{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying all the imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool, tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from dotenv import load_dotenv\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser, ListOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dotenv and specifying tools\n",
    "load_dotenv()\n",
    "\n",
    "def get_numbers(query: str):\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "    template = \"\"\"\n",
    "    You are smart agent that can idenify all the client ids to solve the query. \n",
    "    If no start point for a client is mentioned, assume client 1 is the first client.\n",
    "    id. From the query, return all the ids that the query refers to as a list of integers.\n",
    "    {format_instructions}\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    class Numbers(BaseModel):\n",
    "        numbers: str = Field(description=\"should say 'the numbers extracted from the query'\")\n",
    "        relevant_numbers: list = Field(description=\"should be a list of all the relevant numbers the llm has picked up\")\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=Numbers)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = ['query'],\n",
    "        template=template,\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "    ans = chain.invoke(query)\n",
    "    return ans['relevant_numbers']\n",
    "        \n",
    "\n",
    "@tool\n",
    "def search_tool(query : str):\n",
    "    \"\"\" \n",
    "    Takes a user query and performs an online search to provide\n",
    "    an answer to that query.\n",
    "    \"\"\"\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    answer = search.run(query)\n",
    "    return answer\n",
    "\n",
    "@tool\n",
    "def create_embeddings(query : str):\n",
    "    \"\"\"\n",
    "    Uses the content from the file path to create embeddings on the inputted data. Using the query\n",
    "    provided, perform a similarity search on the query and return the output. If you can not provide a response,\n",
    "    say I don't know rather than providing an incorrect response.\n",
    "    \"\"\"\n",
    "\n",
    "    #file_path = r'C:\\GenAI\\Final Project\\GenAIGroupProject\\apple.txt'\n",
    "    file_path = r'./apple.txt'\n",
    "    file_path = file_path.strip()\n",
    "    loader = TextLoader(file_path, encoding= 'utf-8')\n",
    "    document = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunk = text_splitter.split_documents(documents=document)\n",
    "    embeddings = OpenAIEmbeddings(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    vectorstore = FAISS.from_documents(chunk, embeddings)\n",
    "\n",
    "    docs = vectorstore.similarity_search(query)\n",
    "    return docs[0].page_content\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_database(query : str):\n",
    "    \"\"\"\n",
    "    This function queries the SQL database based on the query that the user inputs.\n",
    "    This will provide insight into the current client(s) stock portfolio from the portfolio table in the database.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0)\n",
    "    db = SQLDatabase.from_uri('sqlite:///portfolio_allocations.db')\n",
    "    agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)\n",
    "    result = agent_executor.invoke(query)\n",
    "\n",
    "    client = get_numbers(query)\n",
    "    for i in client:\n",
    "        response_schemas = [\n",
    "        ResponseSchema(name=f'client {i}', description=f\"A dictionary containing the stock tickers and their percentage allocations for each client {i}.\")\n",
    "        ]\n",
    "      \n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    template=\"create a new key, value pair for every client mentioned in the question.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    ans = chain.invoke({\"question\": result})\n",
    "\n",
    "    if not isinstance(ans, dict):\n",
    "        ans = {\"numbers\": \"the numbers extracted from the query\", \"relevant_numbers\": ans}\n",
    "    \n",
    "    return ans\n",
    "\n",
    "\n",
    "@tool\n",
    "def portfolio_allocation(query : str):\n",
    "    # \"\"\"\n",
    "    # Based on the allocation stratergy provided as a query, change the allocation in the\n",
    "    # client stock portfolio in the SQL database\n",
    "    # \"\"\"\n",
    "    \"\"\"\n",
    "    Based on the allocation stratergy provided as a query, context on the comapany's recent financials from their 10-k reports\n",
    "    and their up-to-date status from an online search, change the allocation in the\n",
    "    client stock portfolios in the SQL database.\n",
    "    \"\"\"\n",
    " \n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant who is going to allocate different weights based on context and the invest stratergy that user wants.\n",
    "    In order to retreieve the context, use the search_tool and the create_embedding tool to search 'Tell me about the fininical siutuation of\n",
    "    AAPL, MSFT, NVIDIA'. Combining this with the allocation stratergy that the user picks, redistribute the allocation percentages. Give exact figures \n",
    "    as to how this is to be used for each stock. You should also give a detailed explanation as to why you came up with these figures. Use the context\n",
    "    to provide statistics in order to boost your reasoning. Make sure the reasoning is also returned in the final answwer.\n",
    "\n",
    "    Query : {query}\n",
    "    {answer}\n",
    "    \"\"\"\n",
    "   \n",
    "    examples = [\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a balanced strategy',\n",
    "        'answer': 'The stock allocations for client_id 1 equal across all stocks, totalling 100.'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a risk-based strategy',\n",
    "        # 'answer': \"\"\"\n",
    "        #             Allocating more to stocks with lower perceived risk. \n",
    "        #             From my 10k data and online search, AAPL has strong financials\n",
    "        #             and minimal risk but NVIDIA has more risk. As a result, the stock\n",
    "        #             allocation for client_id 1 would have a high percentage for AAPL\n",
    "        #             and a low percentage for NVIDIA.\n",
    "        #             \"\"\"\n",
    "        'answer': \"\"\"\n",
    "                        Allocating more to stocks with lower perceived risk. \n",
    "                        From my 10k data and online search, AAPL has strong financials\n",
    "                        and minimal risk but NVIDIA has more risk. As a result, the stock\n",
    "                        allocation fror client_id 1 would have a higher percentage for AAPL\n",
    "                        and a lower percentage for NVIDIA. MSFT would make up the rest of the portfolio.\n",
    "                        \"\"\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a return-based strategy',\n",
    "        # 'answer': \"\"\"\n",
    "        #             Allocating more to stocks with higher expected returns.\n",
    "        #             From my 10k data and online search, NVIDIA has higher expected growth rates and returns\n",
    "        #             whereas AAPL has a declining industry position and poor management quality. As a result, the stock\n",
    "        #             allocation for client_id 1 would have a high percentage for NVIDIA\n",
    "        #             and a low percentage for AAPL\n",
    "        #             \"\"\"\n",
    "        'answer' : \"\"\"\n",
    "                        Allocating more to stocks with higher expected returns.\n",
    "                        From my 10k data and online search, NVIDIA has higher expected growth rates and returns\n",
    "                        whereas MSFT has a declining industry position and poor management quality. As a result, the stock\n",
    "                        allocation fror client_id 1 would have a high percentage for NVIDIA\n",
    "                        and a low percentage for MSFT and APPL would make up the rest of the portfolio.\n",
    "                        \"\"\"\n",
    "    }\n",
    "    ]\n",
    "    c1 = create_embeddings(\"what is the current financial outlook of AAPL, MSFT, NVIDIA\")\n",
    "    c2 = search_tool(\"what is the current financial outlook of AAPL, MSFT, NVIDIA\")\n",
    "\n",
    "    context = c1 + c2\n",
    "\n",
    "    example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"], template=template\n",
    "    )\n",
    "\n",
    "    prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Query: {input}, Context: {context}\",\n",
    "    input_variables=[\"input\", \"context\"],\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "\n",
    "    chain = prompt | llm\n",
    "\n",
    "    print(f\"context: {context}\")\n",
    "    ans = chain.invoke({'input' : query, 'context':context})\n",
    "\n",
    "    return ans.content\n",
    "\n",
    "    \n",
    "tools = [Tool(name=\"search_tool\", func=search_tool, description=\"Tool for performing online search operations\"),\n",
    "         Tool(name=\"create_embeddings\", func=create_embeddings, description=\"Uses the content from the file path to create embeddings on the inputted data. Using the query provided, perform a similarity search on the query and return the output. If you can not provide a response,say I don't know rather than providing an incorrect response.\"),\n",
    "         Tool(name='query_database', func=query_database, description= \"This function queries the SQL database based on the query that the user provides to provide insight into the current client stock portfolio\"),\n",
    "         Tool(name='portfolio_allocation', func=portfolio_allocation, description='This function uses context from the vector database and online searches as well as the investment stratergy the user specifies to determine the stock allocation splits')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GenAIProject\\GenAIGroupProject\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the portfolio_allocation tool to reallocate stocks for client 1 based on a risk-based strategy.\n",
      "\n",
      "Action: portfolio_allocation\n",
      "\n",
      "Action Input: {\"client\": 1, \"strategy\": \"risk-based\"}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GenAIProject\\GenAIGroupProject\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "c:\\GenAIProject\\GenAIGroupProject\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: the aggregate have a material impact on the Companys financial condition or operating results The outcome of litigation is inherently uncertain If one or more legal matters were resolved against the Company in a reporting period for amounts above managements expectations the Companys financial condition and operating results for that reporting period could be materially adversely affectedItem 4    Mine Safety DisclosuresNot applicableApple Inc  2022 Form 10K  17PART IIItem 5    Market for Registrants Common Equity Related Stockholder Matters and Issuer Purchases of Equity SecuritiesThe Companys common stock is traded on The Nasdaq Stock Market LLC under the symbol AAPLHoldersAs of October 14 2022 there were 23838 shareholders of recordPurchases of Equity Securities by the Issuer and Affiliated PurchasersShare repurchase activity during the three months ended September 24 2022 was as follows in millions except number of shares which are reflected in thousands and per shareNvidia also has extremely high operating margins -- higher than any other \"Magnificent Seven\" company -- a term that refers to large, industry-leading growth stocks Microsoft, Apple, Nvidia ... Microsoft is the largest company by market value, at $3.17 trillion. ... (Nvidia's current chips) demand should help alleviate investor concerns about customers potentially delaying purchases in ... The 'Magnificent 7' stocks, including Apple AAPL, Amazon AMZN, Microsoft MSFT, Meta META and Nvidia NVDA, were again significant contributors to growth in 2023 Q4. Please note that two of the ... Nvidia's data center revenue has grown more than 676%, from $2.37 billion in fiscal Q2 2022 to $18.40 billion in fiscal Q4 2024. See why NVDA stock is a buy. Nvidia Corporation's strong Q1 performance prompted a surge in shares, fueled by increased revenues and dividend raise. Read more on NVDA stock update.\n",
      "\u001b[36;1m\u001b[1;3mBased on the context provided and the risk-based strategy, the stock allocation for client 1 should be as follows:\n",
      "\n",
      "- AAPL: 40%\n",
      "- MSFT: 30%\n",
      "- NVIDIA: 30%\n",
      "\n",
      "Reasoning:\n",
      "- AAPL: From the information gathered, AAPL has strong financials and minimal risk. This makes it a safer investment option, hence the higher allocation percentage of 40%.\n",
      "- MSFT: Microsoft is the largest company by market value and is considered a stable investment. While it may have some risk, it is lower compared to NVIDIA. Therefore, a moderate allocation of 30% is appropriate.\n",
      "- NVIDIA: NVIDIA has higher perceived risk due to its volatile nature and high operating margins. Despite its potential for growth and higher expected returns, it also comes with higher risk. Hence, a lower allocation of 30% is recommended to manage risk exposure for client 1.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: \n",
      "Based on a risk-based strategy, the stock allocation for client 1 should be:\n",
      "- AAPL: 40%\n",
      "- MSFT: 30%\n",
      "- NVIDIA: 30%\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on a risk-based strategy, the stock allocation for client 1 should be:\n",
      "- AAPL: 40%\n",
      "- MSFT: 30%\n",
      "- NVIDIA: 30%\n"
     ]
    }
   ],
   "source": [
    "# template = \"\"\"\n",
    "# You need to use the tools to find the appropriate action to take. \n",
    "\n",
    "# Only use the query_database and portfolio_allocation tools when the term \"portfolio\" is mentioned in the query.\n",
    "\n",
    "# If further queries are presented alongside the term \"portfilio\", then use all tools available.\n",
    "# Otherwise, ignore these two tools and use the embeddings first\n",
    "# to see if you can get relevant responses from the similarity search from the user's query. If you do get relevant\n",
    "# responses, please return the responses from the similarity search. If you can't get relevent results from the embeddings,\n",
    "# use the seatch tool and get the reponse from there. If you still can't find an answer from an online search, please do not make up an\n",
    "# answer and return 'Sorry I can not answer your query' instead.\n",
    "\n",
    "\n",
    "# You have access to the following tools:\n",
    "# {tools}\n",
    "\n",
    "# Question: the input question you must answer\n",
    "\n",
    "# Thought: you should always think about what to do\n",
    "\n",
    "# Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "# Action Input: the input to the action\n",
    "\n",
    "# Observation: the result of the action\n",
    "\n",
    "# ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "# Thought: I now know the final answer\n",
    "\n",
    "# If only the query_database tool is used, treat the tool as a function and return the full dictionary in the final answer.\n",
    "# For the values, ensure than every ticker(e.g. AAPL) is a key with the value pair being its stock allocation. If quieried for\n",
    "# multiple clients, data about ALL clients should be included. For example if allocations are asked for 'clients 1 and 2',\n",
    "# the allocations for BOTH of these clients should be returned and if the allocations are asked for 'all clients up to client 3',\n",
    "# the allocations for clients 1,2 and 3 should be returned and NOT just the allocations for client 3.\n",
    "\n",
    "# Similarly, if portfolio_allocation is used, return EXACTLY what is returned from the portfolio_allocation function.\n",
    "\n",
    "\n",
    "# Final Answer: the final answer to the original input question\n",
    "\n",
    "# Begin!\n",
    "\n",
    "# Question: {input}\n",
    "\n",
    "# Thought:{agent_scratchpad}\n",
    "# \"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You need to use the tools to find the appropriate action to take. \n",
    "\n",
    "If you are searching for information use the create_emebddings tool FIRST.\n",
    "\n",
    "Only use the query_database and portfolio_allocation tools when the term \"clients\" is mentioned in the query \n",
    "and if further queries are presented alongside the term \"clients\", then use all tools available.\n",
    "\n",
    "Try to get relevant responses within our internal documents. If you get relevant\n",
    "responses, return them to the user. \n",
    "\n",
    "If you do not get relevent results from the embeddings, use the search_tool to get responses from the internet.\n",
    "\n",
    "If you still can't find an answer from an online search, \n",
    "please do not make up an answer and return 'Sorry I cannot answer your query' instead.\n",
    "\n",
    "If performing portfolio_allocation, use the tools \"search_tool\" and \"create_embeddings\" \n",
    "to get context around AAPL, MSFT, NVIDIA's financial situation. \n",
    "Use a query with these tools that states: \"Tell me about the company's financial situation\". \n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "If your thought before the final answer includes the output from the portfolio_allocation tool, give the response by including ACTUAL percentages totalling to 100. \n",
    "\n",
    "If your thought before the final answer uses the query_database tool, treat the tool as a function and return a dictionary output as the final answer.\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the query and create the prompt\n",
    "#query = 'return the values for client_id 1 in the sql database and also tell me the current apple stock price'\n",
    "#query = 'Tell me the current apple stock price'\n",
    "#query = 'Return me the stock allocation for client 5'\n",
    "#query = 'Return me the stock allocation for client 3 and client 7 and client 5'\n",
    "#query = 'Return me the stock allocation for every client'\n",
    "#query = 'give me all the stock allocations from all clients up to client 3'\n",
    "#query = \"The Company continues to develop new technologies to enhance existing products and services and to expand the range of its offerings through research and development RD licensing of intellectual property and acquisition of thirdparty businesses and technology\"\n",
    "#query = \"Give me a sentence from the apple 10-k report\"\n",
    "#query = \"what is the net sales of iPhones in 2021\"\n",
    "#query =  \"add a new client to the database with random stock allocations, provide the sql query to do so and execute it\"\n",
    "#query =  \"set the stock allocations for client_id 1 to 5,5,90. provide the sql query to do so and execute it on the database\" #remeber to pull numbers from another query into this framework\n",
    "#query = 'give me all the stock allocations from all clients up to client 3'\n",
    "#query = 'give me all the stock allocations for all clients up to client 3'\n",
    "query = 'Reallocate the stocks for client 1 using a risk-based stratergy'\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['input','tools', 'agent_scratchpad', 'tool_names'], template=template)\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "\n",
    "\n",
    "# Create the agent using the language model and the toolset\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# Execute the agent with the given input\n",
    "response = agent_executor.invoke({'input': query, 'tools' : tools, 'tool_names' : [tool.name for tool in tools]})\n",
    "\n",
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
