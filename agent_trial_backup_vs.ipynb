{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying all the imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool, tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from dotenv import load_dotenv\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser, ListOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dotenv and specifying tools\n",
    "load_dotenv()\n",
    "\n",
    "def get_numbers(query: str):\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "    template = \"\"\"\n",
    "    You are smart agent that can idenify all the client ids to solve the query. \n",
    "    If no start point for a client is mentioned, assume client 1 is the first client.\n",
    "    id. From the query, return all the ids that the query refers to as a list of integers\n",
    "\n",
    "    {format_instructions}\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    class Numbers(BaseModel):\n",
    "        numbers: str = Field(description=\"should say 'the numbers extracted from the query'\")\n",
    "        relevant_numbers: list = Field(description=\"should be a list of all the relevant numbers the llm has picked up\")\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=Numbers)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = ['query'],\n",
    "        template=template,\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    ans = chain.invoke(query)\n",
    "    return ans['relevant_numbers']\n",
    "        \n",
    "\n",
    "@tool\n",
    "def search_tool(query : str):\n",
    "    \"\"\" \n",
    "    Takes a user query and performs an online search to provide\n",
    "    an answer to the query\n",
    "    \"\"\"\n",
    "    \n",
    "    search = DuckDuckGoSearchRun()\n",
    "    answer = search.run(query)\n",
    "    return answer\n",
    "\n",
    "@tool\n",
    "def create_embeddings(query : str):\n",
    "    \"\"\"\n",
    "    Uses the content from the file path to create embeddings on the inputted data. Using the query\n",
    "    provided, perform a similarity search on the query and return the output. If you can not provide a response,\n",
    "    say I don't know rather than providing an incorrect response.\n",
    "    \"\"\"\n",
    "\n",
    "    #file_path = r'C:\\GenAI\\Final Project\\GenAIGroupProject\\apple.txt'\n",
    "    file_path = r'./apple.txt'\n",
    "    file_path = file_path.strip()\n",
    "    loader = TextLoader(file_path, encoding= 'utf-8')\n",
    "    document = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunk = text_splitter.split_documents(documents=document)\n",
    "    embeddings = OpenAIEmbeddings(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    vectorstore = FAISS.from_documents(chunk, embeddings)\n",
    "\n",
    "    docs = vectorstore.similarity_search(query)\n",
    "    return docs[0].page_content\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_database(query : str):\n",
    "    \"\"\"\n",
    "    This function queries the SQL database based on the query that the user provides\n",
    "    to provide insight into the current client stock portfolio\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the JSON output key parser\n",
    "\n",
    "\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0)\n",
    "    db = SQLDatabase.from_uri('sqlite:///client_db')\n",
    "    agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)\n",
    "    result = agent_executor.invoke(query)\n",
    "\n",
    "    # def extract_clients(query: str) -> list:\n",
    "    #     \"\"\"Extract a list of client ids based on the input query.\"\"\"\n",
    "    #     client_numbers = re.findall(r'client (\\d+)', query)\n",
    "    #     clients = [f\"client{i}\" for i in client_numbers]\n",
    "    #     #print(f\"my clients are {clients}\")\n",
    "    #     return clients\n",
    "    \n",
    "    # def extract_clients(query: str) -> list:\n",
    "    #     res = [int(i) for i in query.split() if i.isdigit()]\n",
    "    #     return res\n",
    "\n",
    "    # clients = extract_clients(query)\n",
    "\n",
    "    #clients = [f\"client{i}\" for i in range(1, query.count(\"client\") + 1)]\n",
    "\n",
    "    # Define the response schemas dynamically based on the number of clients\n",
    "    client = get_numbers(query)\n",
    "    for i in client:\n",
    "        response_schemas = [\n",
    "        ResponseSchema(name=f'client {i}', description=f\"A dictionary containing the stock tickers and their percentage allocations for client {i}.\")\n",
    "        ]\n",
    "    \n",
    "    # Initialize the structured output parser\n",
    "    # output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "    # # Get the format instructions\n",
    "    # format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    # # Define the prompt template\n",
    "    # prompt_template = PromptTemplate(\n",
    "    #     template=\"Create a new key, value pair for every new client mentioned in the question.\\n{format_instructions}\\nQuestion: {question}\",\n",
    "    #     input_variables=[\"question\"],\n",
    "    #     partial_variables={\"format_instructions\": format_instructions},\n",
    "    # )\n",
    "\n",
    "    \n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    template=\"create a new key, value pair for every new client mentioned in the question.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    ans = chain.invoke({\"question\": result})\n",
    "\n",
    "    if not isinstance(ans, dict):\n",
    "        ans = {\"numbers\": \"the numbers extracted from the query\", \"relevant_numbers\": ans}\n",
    "    \n",
    "    return ans\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "@tool\n",
    "def portfolio_allocation(query : str):\n",
    "    \"\"\"\n",
    "    Based on the allocation stratergy provided as a query, change the allocation in the\n",
    "    client stock portfolio in the SQL database\n",
    "    \"\"\"\n",
    "    #query = Reallocte the portfolio for client 1 with a balanced strategy\n",
    "\n",
    "    #  1. Read in the client database using the query database tool\n",
    "\n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant who is going to allocate different weights based on context and the invest stratergy that user wants.\n",
    "    In order to retreieve the context, use the search_tool and the create_embedding tool to search 'Tell me about the fininical siutuation of\n",
    "    AAPL, MSFT, NVIDIA'. Combining this with the allocation stratergy that the user picks, redistribute the allocation percentages. Give exact figures \n",
    "    as to how this is to be used for each stock. You should also give a detailed explanation as to why you came up with these figures. Use the context\n",
    "    to provide statistics in order to boost your reasoning. Make sure the reasoning is also returned in the final answwer.\n",
    "\n",
    "    Query : {query}\n",
    "    {answer}\n",
    "    \"\"\"\n",
    "   \n",
    "    examples = [\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a balanced strategy',\n",
    "        'answer': ' The stock allocations for client_id 1 to 33,33,33'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a risk-based strategy',\n",
    "        'answer': \"\"\"\n",
    "                    Allocating more to stocks with lower perceived risk. \n",
    "                    From my 10k data and online search, AAPL has strong financials\n",
    "                    and minimal risk but NVIDIA has more risk. As a result, the stock\n",
    "                    allocation for client_id 1 would have a high percentage for AAPL\n",
    "                    and a low percentage for NVIDIA.\n",
    "                    \"\"\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'query': 'Reallocte the portfolio for client 1 with a return-based strategy',\n",
    "        'answer': \"\"\"\n",
    "                    Allocating more to stocks with higher expected returns.\n",
    "                    From my 10k data and online search, NVIDIA has higher expected growth rates and returns\n",
    "                    whereas AAPL has a declining industry position and poor management quality. As a result, the stock\n",
    "                    allocation for client_id 1 would have a high percentage for NVIDIA\n",
    "                    and a low percentage for AAPL\n",
    "                    \"\"\"\n",
    "    }\n",
    "    ]\n",
    "    \n",
    "    example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"], template=template\n",
    "    )\n",
    "\n",
    "    \n",
    "    #  2. Determine allocation stratergy based on query\n",
    "\n",
    "\n",
    "    #  3. Read in the Financials from the 10k\n",
    "\n",
    "    #  4. Get current information from online\n",
    "\n",
    "    #  5. Apply the stratergy we determined on the information from steps 3 and 4!\n",
    "\n",
    "    #  6. Translate this into a percentage allocation for each company and write to database\n",
    "\n",
    "    prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Query: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "\n",
    "    chain = prompt | llm\n",
    "\n",
    "    ans = chain.invoke({'input' : query})\n",
    "\n",
    "    return ans.content\n",
    "\n",
    "    \n",
    "\n",
    "tools = [Tool(name=\"search_tool\", func=search_tool, description=\"Tool for performing online search operations\"),\n",
    "         Tool(name=\"create_embeddings\", func=create_embeddings, description=\"Uses the content from the file path to create embeddings on the inputted data. Using the query provided, perform a similarity search on the query and return the output. If you can not provide a response,say I don't know rather than providing an incorrect response.\"),\n",
    "         Tool(name='query_database', func=query_database, description= \"This function queries the SQL database based on the query that the user provides to provide insight into the current client stock portfolio\"),\n",
    "         Tool(name='portfolio_allocation', func=portfolio_allocation, description='This function uses context from the vector database and online searches as well as the investment stratergy the user specifies to determine the stock allocation splits')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the query_database tool to retrieve the stock allocations for all clients up to client 3.\n",
      "\n",
      "Action: query_database\n",
      "\n",
      "Action Input: {'query': 'all clients up to client 3'}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mstocks\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'stocks'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE stocks (\n",
      "\tclient_id INTEGER, \n",
      "\t\"AAPL\" INTEGER, \n",
      "\t\"MSFT\" INTEGER, \n",
      "\t\"NVIDIA\" INTEGER, \n",
      "\tPRIMARY KEY (client_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from stocks table:\n",
      "client_id\tAAPL\tMSFT\tNVIDIA\n",
      "1\t5\t5\t90\n",
      "2\t20\t40\t40\n",
      "3\t10\t10\t80\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT client_id, \"AAPL\", \"MSFT\", \"NVIDIA\" FROM stocks WHERE client_id <= 3'}`\n",
      "responded: Based on the schema of the `stocks` table, I can query the client_id and stock values for all clients up to client 3. Here is the query:\n",
      "\n",
      "```sql\n",
      "SELECT client_id, \"AAPL\", \"MSFT\", \"NVIDIA\"\n",
      "FROM stocks\n",
      "WHERE client_id <= 3\n",
      "```\n",
      "\n",
      "I will now execute this query to retrieve the results.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(1, 5, 5, 90), (2, 20, 40, 40), (3, 10, 10, 80)]\u001b[0m\u001b[32;1m\u001b[1;3mThe query results show the client_id and stock values for all clients up to client 3:\n",
      "\n",
      "- Client 1: AAPL - 5, MSFT - 5, NVIDIA - 90\n",
      "- Client 2: AAPL - 20, MSFT - 40, NVIDIA - 40\n",
      "- Client 3: AAPL - 10, MSFT - 10, NVIDIA - 80\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m{'client 3': {'AAPL': 10, 'MSFT': 10, 'NVIDIA': 80}}\u001b[0m\u001b[32;1m\u001b[1;3mI have retrieved the stock allocations for all clients up to client 3.\n",
      "\n",
      "Final Answer: {'client 3': {'AAPL': 10, 'MSFT': 10, 'NVIDIA': 80}}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'client 3': {'AAPL': 10, 'MSFT': 10, 'NVIDIA': 80}}\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You need to use the tools to find the appropriate action to take. \n",
    "Only use the query_database and portfolio_allocation tools when the term \"portfolio\" is mentioned in the query.\n",
    "\n",
    "If further queries are presented alongside the term \"portfilio\", then use all tools available.\n",
    "Otherwise, ignore these two tools and use the embeddings first\n",
    "to see if you can get relevant responses from the similarity search from the user's query. If you do get relevant\n",
    "responses, please return the responses from the similarity search. If you can't get relevent results from the embeddings,\n",
    "use the seatch tool and get the reponse from there. If you still can't find an answer from an online search, please do not make up an\n",
    "answer and return 'Sorry I can not answer your query' instead.\n",
    "\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "If only the query_database tool is used, treat the tool as a function and return the full dictionary in the final answer.\n",
    "For the values, ensure than every ticker(e.g. AAPL) is a key with the value pair being its stock allocation. If quieried for\n",
    "multiple clients, data about ALL clients should be included. For example if allocations are asked for 'clients 1 and 2',\n",
    "the allocations for BOTH of these clients should be returned and if the allocations are asked for 'all clients up to client 3',\n",
    "the allocations for clients 1,2 and 3 should be returned and NOT just the allocations for client 3.\n",
    "\n",
    "Similarly, if portfolio_allocation is used, return EXACTLY what is returned from the portfolio_allocation function.\n",
    "\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Define the query and create the prompt\n",
    "#query = 'return the values for client_id 1 in the sql database and also tell me the current apple stock price'\n",
    "#query = 'Tell me the current apple stock price'\n",
    "#query = 'Return me the stock allocation for client 1, client 2, and client 3'\n",
    "#query = 'Return me the stock allocation for client 3 and client 7 and client 5'\n",
    "#query = 'Return me the stock allocation for every client'\n",
    "# query = 'give me all the stock allocations from all clients up to client 3'\n",
    "#query = \"The Company continues to develop new technologies to enhance existing products and services and to expand the range of its offerings through research and development RD licensing of intellectual property and acquisition of thirdparty businesses and technology\"\n",
    "#query = \"Give me a sentence from the apple 10-k report\"\n",
    "#query = \"what is the net sales of Macs in 2021\"\n",
    "#query =  \"add a new client to the database with random stock allocations, provide the sql query to do so and execute it\"\n",
    "#query =  \"set the stock allocations for client_id 1 to 5,5,90. provide the sql query to do so and execute it on the database\" #remeber to pull numbers from another query into this framework\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# query = 'give me all the stock allocations from all clients up to client 3'\n",
    "query = 'give me all the stock allocations for all clients up to client 3'\n",
    "# query = 'Reallocate the stocks for client 1 using a risk-based stratergy'\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['input','tools', 'agent_scratchpad', 'tool_names'], template=template)\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-3.5-turbo', temperature=0.2)\n",
    "\n",
    "\n",
    "# Create the agent using the language model and the toolset\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# Execute the agent with the given input\n",
    "response = agent_executor.invoke({'input': query, 'tools' : tools, 'tool_names' : [tool.name for tool in tools]})\n",
    "\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_numbers('give me all the stock allocations for all clients up to client 3')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on a return-based strategy, the stock allocation for client 1 would be skewed towards NVIDIA due to its higher expected growth rates and returns compared to AAPL. Therefore, the allocation percentages would be higher for NVIDIA and lower for AAPL. Specific figures for the allocation could be 40% for NVIDIA and 20% for AAPL, with the remaining 40% allocated to MSFT.\n",
      "\n",
      "This allocation is based on the analysis of the financial situation of the three stocks. NVIDIA has been showing strong growth potential and is expected to continue performing well in the future, making it a favorable choice for higher allocation. On the other hand, AAPL has been facing challenges in terms of industry position and management quality, leading to a lower allocation percentage.\n",
      "\n",
      "By reallocating the portfolio in this manner, the client can potentially maximize their returns by capitalizing on the growth opportunities presented by NVIDIA while minimizing exposure to the risks associated with AAPL.\n"
     ]
    }
   ],
   "source": [
    "x = portfolio_allocation('Reallocte the portfolio for client 1 with a return.-based strategy')\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
