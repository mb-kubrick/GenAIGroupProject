{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development: ML Flow\n",
    "\n",
    "File for developing the mlflow code for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Use the below lines if any dependencies are missing.\n",
    "# ! python -m pip install uv\n",
    "# ! python -m uv pip install langchain_openai mlflow load_dotenv langchain pandas langchain_community\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('\\\\'.join(os.getcwd().split('\\\\')[:-1])))\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from mlflow.metrics.genai import make_genai_metric, EvaluationExample\n",
    "from ml_flow import mlflow_server, create_example_llm, evaluate_llm, delete_runs\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we run the ML-Flow server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_process = mlflow_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate a dummy LLM which will answer simple queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.agents import create_react_agent, AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.17-py3-none-any.whl (4.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\code\\genaigroupproject\\.venv\\lib\\site-packages (from langchainhub) (2.32.2)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2\n",
      "  Downloading types_requests-2.32.0.20240523-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\code\\genaigroupproject\\.venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\code\\genaigroupproject\\.venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\code\\genaigroupproject\\.venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\code\\genaigroupproject\\.venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.17 types-requests-2.32.0.20240523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m We should use the Ionic Commerce Shopping Tool to find 4k monitors.\n",
      "Action: ionic_commerce_shopping_tool\n",
      "Action Input: 4k monitors, 4, 0, 100000\u001b[0m\u001b[36;1m\u001b[1;3m[{'products': [{'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://l.ioniccommerce.com/aeegg7'}], 'merchant_name': 'Best Buy', 'merchant_product_id': '6386391', 'name': '28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor', 'price': '$199.99', 'status': 'available', 'thumbnail': 'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg', 'brand_name': 'Samsung', 'upc': '887276374888'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B098HQ8YRX', 'name': 'Sceptre 4K IPS 27\" 3840 x 2160 UHD Monitor up to 70Hz DisplayPort HDMI 99% sRGB Build-in Speakers, Black 2021 (U275W-UPT)', 'price': '$179.97', 'status': 'available', 'thumbnail': 'https://m.media-amazon.com/images/I/41URcXrndAL._SL160_.jpg', 'brand_name': 'Sceptre', 'upc': '792343327752'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B084V9CJB1?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B084V9CJB1', 'name': 'SAMSUNG 28-Inch ViewFinity UR55 Series 4K UHD IPS Computer Monitor, HDR10, AMD FreeSync, HDMI 2.0 and DisplayPort 1.2, Bezelless Display, Eye Care, LU28R550UQNXZA, 2023', 'price': '$199.99', 'status': 'available', 'thumbnail': 'https://m.media-amazon.com/images/I/41etykq-WqL._SL160_.jpg', 'brand_name': 'SAMSUNG', 'upc': '887276374888'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B07PGL2WVS?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B07PGL2WVS', 'name': 'LG 27UL500-W 27-inch 4K UHD (3840 x 2160) UltraFine Computer Monitor, IPS, AMD FreeSync, HDR10, HDMI, DisplayPort, Black Stabilizer, White', 'price': '$249.99', 'status': 'available', 'thumbnail': 'https://m.media-amazon.com/images/I/41sBz19TaiL._SL160_.jpg', 'brand_name': 'LG', 'upc': '719192629813'}], 'query': {'query': '4k monitors', 'max_price': 100000, 'min_price': 0, 'num_results': 4}}]\u001b[0m\u001b[32;1m\u001b[1;3m We should format the result as a markdown list with each recommendation being a numbered list item.\n",
      "Action: Format as markdown list\n",
      "Action Input: [{'products': [{'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://l.ioniccommerce.com/aeegg7'}], 'merchant_name': 'Best Buy', 'merchant_product_id': '6386391', 'name': '28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor', 'price': '$199.99', 'status': 'available', 'thumbnail': 'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg', 'brand_name': 'Samsung', 'upc': '887276374888'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B098HQ8YRX', 'name': 'Sceptre 4K IPS 27\" 3840\u001b[0mFormat as markdown list is not a valid tool, try one of [ionic_commerce_shopping_tool].\u001b[32;1m\u001b[1;3m We can use the observed result as the input for the markdown list.\n",
      "Action: Use observed result as input for markdown list\n",
      "Action Input: [{'products': [{'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://l.ioniccommerce.com/aeegg7'}], 'merchant_name': 'Best Buy', 'merchant_product_id': '6386391', 'name': '28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor', 'price': '$199.99', 'status': 'available', 'thumbnail': 'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg', 'brand_name': 'Samsung', 'upc': '887276374888'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B098HQ8YRX', 'name': 'Sceptre 4K IPS 27\" 3840\u001b[0mUse observed result as input for markdown list is not a valid tool, try one of [ionic_commerce_shopping_tool].\u001b[32;1m\u001b[1;3m The input for the ionic_commerce_shopping_tool is a comma-separated string of values.\n",
      "Action: Check if the input is a comma-separated string of values\n",
      "Action Input: 'coffee beans, 5, 500, 1000'\u001b[0mCheck if the input is a comma-separated string of values is not a valid tool, try one of [ionic_commerce_shopping_tool].\u001b[32;1m\u001b[1;3m The input for the ionic_commerce_shopping_tool should be a query string, number of results, minimum price, and maximum price.\n",
      "Action: Check if the input includes all required values\n",
      "Action Input: 'coffee beans, 5, 500, 1000'\u001b[0mCheck if the input includes all required values is not a valid tool, try one of [ionic_commerce_shopping_tool].\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"I'm looking for a new 4k monitor can you find me some options for less than $1000\", 'output': 'Agent stopped due to iteration limit or time limit.', 'intermediate_steps': [(AgentAction(tool='ionic_commerce_shopping_tool', tool_input='4k monitors, 4, 0, 100000', log=' We should use the Ionic Commerce Shopping Tool to find 4k monitors.\\nAction: ionic_commerce_shopping_tool\\nAction Input: 4k monitors, 4, 0, 100000'), [{'products': [{'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://l.ioniccommerce.com/aeegg7'}], 'merchant_name': 'Best Buy', 'merchant_product_id': '6386391', 'name': '28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor', 'price': '$199.99', 'status': 'available', 'thumbnail': 'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg', 'brand_name': 'Samsung', 'upc': '887276374888'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B098HQ8YRX', 'name': 'Sceptre 4K IPS 27\" 3840 x 2160 UHD Monitor up to 70Hz DisplayPort HDMI 99% sRGB Build-in Speakers, Black 2021 (U275W-UPT)', 'price': '$179.97', 'status': 'available', 'thumbnail': 'https://m.media-amazon.com/images/I/41URcXrndAL._SL160_.jpg', 'brand_name': 'Sceptre', 'upc': '792343327752'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B084V9CJB1?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B084V9CJB1', 'name': 'SAMSUNG 28-Inch ViewFinity UR55 Series 4K UHD IPS Computer Monitor, HDR10, AMD FreeSync, HDMI 2.0 and DisplayPort 1.2, Bezelless Display, Eye Care, LU28R550UQNXZA, 2023', 'price': '$199.99', 'status': 'available', 'thumbnail': 'https://m.media-amazon.com/images/I/41etykq-WqL._SL160_.jpg', 'brand_name': 'SAMSUNG', 'upc': '887276374888'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B07PGL2WVS?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B07PGL2WVS', 'name': 'LG 27UL500-W 27-inch 4K UHD (3840 x 2160) UltraFine Computer Monitor, IPS, AMD FreeSync, HDR10, HDMI, DisplayPort, Black Stabilizer, White', 'price': '$249.99', 'status': 'available', 'thumbnail': 'https://m.media-amazon.com/images/I/41sBz19TaiL._SL160_.jpg', 'brand_name': 'LG', 'upc': '719192629813'}], 'query': {'query': '4k monitors', 'max_price': 100000, 'min_price': 0, 'num_results': 4}}]), (AgentAction(tool='Format as markdown list', tool_input='[{\\'products\\': [{\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://l.ioniccommerce.com/aeegg7\\'}], \\'merchant_name\\': \\'Best Buy\\', \\'merchant_product_id\\': \\'6386391\\', \\'name\\': \\'28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor\\', \\'price\\': \\'$199.99\\', \\'status\\': \\'available\\', \\'thumbnail\\': \\'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg\\', \\'brand_name\\': \\'Samsung\\', \\'upc\\': \\'887276374888\\'}, {\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1\\'}], \\'merchant_name\\': \\'Amazon\\', \\'merchant_product_id\\': \\'B098HQ8YRX\\', \\'name\\': \\'Sceptre 4K IPS 27\" 3840', log=' We should format the result as a markdown list with each recommendation being a numbered list item.\\nAction: Format as markdown list\\nAction Input: [{\\'products\\': [{\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://l.ioniccommerce.com/aeegg7\\'}], \\'merchant_name\\': \\'Best Buy\\', \\'merchant_product_id\\': \\'6386391\\', \\'name\\': \\'28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor\\', \\'price\\': \\'$199.99\\', \\'status\\': \\'available\\', \\'thumbnail\\': \\'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg\\', \\'brand_name\\': \\'Samsung\\', \\'upc\\': \\'887276374888\\'}, {\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1\\'}], \\'merchant_name\\': \\'Amazon\\', \\'merchant_product_id\\': \\'B098HQ8YRX\\', \\'name\\': \\'Sceptre 4K IPS 27\" 3840'), 'Format as markdown list is not a valid tool, try one of [ionic_commerce_shopping_tool].'), (AgentAction(tool='Use observed result as input for markdown list', tool_input='[{\\'products\\': [{\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://l.ioniccommerce.com/aeegg7\\'}], \\'merchant_name\\': \\'Best Buy\\', \\'merchant_product_id\\': \\'6386391\\', \\'name\\': \\'28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor\\', \\'price\\': \\'$199.99\\', \\'status\\': \\'available\\', \\'thumbnail\\': \\'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg\\', \\'brand_name\\': \\'Samsung\\', \\'upc\\': \\'887276374888\\'}, {\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1\\'}], \\'merchant_name\\': \\'Amazon\\', \\'merchant_product_id\\': \\'B098HQ8YRX\\', \\'name\\': \\'Sceptre 4K IPS 27\" 3840', log=' We can use the observed result as the input for the markdown list.\\nAction: Use observed result as input for markdown list\\nAction Input: [{\\'products\\': [{\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://l.ioniccommerce.com/aeegg7\\'}], \\'merchant_name\\': \\'Best Buy\\', \\'merchant_product_id\\': \\'6386391\\', \\'name\\': \\'28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor\\', \\'price\\': \\'$199.99\\', \\'status\\': \\'available\\', \\'thumbnail\\': \\'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg\\', \\'brand_name\\': \\'Samsung\\', \\'upc\\': \\'887276374888\\'}, {\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1\\'}], \\'merchant_name\\': \\'Amazon\\', \\'merchant_product_id\\': \\'B098HQ8YRX\\', \\'name\\': \\'Sceptre 4K IPS 27\" 3840'), 'Use observed result as input for markdown list is not a valid tool, try one of [ionic_commerce_shopping_tool].'), (AgentAction(tool='Check if the input is a comma-separated string of values', tool_input=\"'coffee beans, 5, 500, 1000'\", log=\" The input for the ionic_commerce_shopping_tool is a comma-separated string of values.\\nAction: Check if the input is a comma-separated string of values\\nAction Input: 'coffee beans, 5, 500, 1000'\"), 'Check if the input is a comma-separated string of values is not a valid tool, try one of [ionic_commerce_shopping_tool].'), (AgentAction(tool='Check if the input includes all required values', tool_input=\"'coffee beans, 5, 500, 1000'\", log=\" The input for the ionic_commerce_shopping_tool should be a query string, number of results, minimum price, and maximum price.\\nAction: Check if the input includes all required values\\nAction Input: 'coffee beans, 5, 500, 1000'\"), 'Check if the input includes all required values is not a valid tool, try one of [ionic_commerce_shopping_tool].')]}\n"
     ]
    }
   ],
   "source": [
    "from ionic_langchain.tool import Ionic, IonicTool\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, Tool, create_react_agent\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Based on ReAct Agent\n",
    "# https://python.langchain.com/docs/modules/agents/agent_types/react\n",
    "# Please reach out to support@ionicapi.com for help with add'l agent types.\n",
    "\n",
    "\n",
    "model = \"gpt-3.5-turbo-instruct\"\n",
    "temperature = 0.6\n",
    "\n",
    "llm = OpenAI(model_name=model, temperature=temperature)\n",
    "\n",
    "\n",
    "ionic_tool = IonicTool().tool()\n",
    "\n",
    "\n",
    "# The tool comes with its own prompt,\n",
    "# but you may also update it directly via the description attribute:\n",
    "\n",
    "ionic_tool.description = str(\n",
    "    \"\"\"\n",
    "Ionic is an e-commerce shopping tool. Assistant uses the Ionic Commerce Shopping Tool to find, discover, and compare products from thousands of online retailers. Assistant should use the tool when the user is looking for a product recommendation or trying to find a specific product.\n",
    "\n",
    "The user may specify the number of results, minimum price, and maximum price for which they want to see results.\n",
    "Ionic Tool input is a comma-separated string of values:\n",
    "  - query string (required, must not include commas)\n",
    "  - number of results (default to 4, no more than 10)\n",
    "  - minimum price in cents ($5 becomes 500)\n",
    "  - maximum price in cents\n",
    "For example, if looking for coffee beans between 5 and 10 dollars, the tool input would be `coffee beans, 5, 500, 1000`.\n",
    "\n",
    "Return them as a markdown formatted list with each recommendation from tool results, being sure to include the full PDP URL. For example:\n",
    "\n",
    "1. Product 1: [Price] -- link\n",
    "2. Product 2: [Price] -- link\n",
    "3. Product 3: [Price] -- link\n",
    "4. Product 4: [Price] -- link\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "tools = [ionic_tool]\n",
    "\n",
    "# default prompt for create_react_agent\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, handle_parsing_errors=True, verbose=True, max_iterations=5, return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "input = (\"I'm looking for a new 4k monitor can you find me some options for less than $1000\")\n",
    "result = agent_executor.invoke({\"input\": input})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: ionic_commerce_shopping_tool\n",
      "Log:  We should use the Ionic Commerce Shopping Tool to find 4k monitors.\n",
      "Action: ionic_commerce_shopping_tool\n",
      "Action Input: 4k monitors, 4, 0, 100000\n",
      "\n",
      "\n",
      "Tool: Format as markdown list\n",
      "Log:  We should format the result as a markdown list with each recommendation being a numbered list item.\n",
      "Action: Format as markdown list\n",
      "Action Input: [{'products': [{'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://l.ioniccommerce.com/aeegg7'}], 'merchant_name': 'Best Buy', 'merchant_product_id': '6386391', 'name': '28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor', 'price': '$199.99', 'status': 'available', 'thumbnail': 'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg', 'brand_name': 'Samsung', 'upc': '887276374888'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B098HQ8YRX', 'name': 'Sceptre 4K IPS 27\" 3840\n",
      "\n",
      "\n",
      "Tool: Use observed result as input for markdown list\n",
      "Log:  We can use the observed result as the input for the markdown list.\n",
      "Action: Use observed result as input for markdown list\n",
      "Action Input: [{'products': [{'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://l.ioniccommerce.com/aeegg7'}], 'merchant_name': 'Best Buy', 'merchant_product_id': '6386391', 'name': '28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor', 'price': '$199.99', 'status': 'available', 'thumbnail': 'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg', 'brand_name': 'Samsung', 'upc': '887276374888'}, {'links': [{'text': 'Details', 'type': 'pdp', 'url': 'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1'}], 'merchant_name': 'Amazon', 'merchant_product_id': 'B098HQ8YRX', 'name': 'Sceptre 4K IPS 27\" 3840\n",
      "\n",
      "\n",
      "Tool: Check if the input is a comma-separated string of values\n",
      "Log:  The input for the ionic_commerce_shopping_tool is a comma-separated string of values.\n",
      "Action: Check if the input is a comma-separated string of values\n",
      "Action Input: 'coffee beans, 5, 500, 1000'\n",
      "\n",
      "\n",
      "Tool: Check if the input includes all required values\n",
      "Log:  The input for the ionic_commerce_shopping_tool should be a query string, number of results, minimum price, and maximum price.\n",
      "Action: Check if the input includes all required values\n",
      "Action Input: 'coffee beans, 5, 500, 1000'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "\n",
    "for step in result['intermediate_steps']:\n",
    "    context += [f'Tool: {step[0].tool}']\n",
    "    context += [f'Log: {step[0].log}']\n",
    "    context += '\\n'\n",
    "\n",
    "print('\\n'.join(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check if the input includes all required values'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['intermediate_steps'][4][0].tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' We should use the Ionic Commerce Shopping Tool to find 4k monitors.\\nAction: ionic_commerce_shopping_tool\\nAction Input: 4k monitors, 4, 0, 100000'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['intermediate_steps'][0][0].log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '4k monitors', 'max_price': 100000, 'min_price': 0, 'num_results': 4}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['intermediate_steps'][0][1][0]['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' We can use the observed result as the input for the markdown list.\\nAction: Use observed result as input for markdown list\\nAction Input: [{\\'products\\': [{\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://l.ioniccommerce.com/aeegg7\\'}], \\'merchant_name\\': \\'Best Buy\\', \\'merchant_product_id\\': \\'6386391\\', \\'name\\': \\'28” ViewFinity UHD IPS AMD FreeSync with HDR Monitor\\', \\'price\\': \\'$199.99\\', \\'status\\': \\'available\\', \\'thumbnail\\': \\'https://pisces.bbystatic.com/image2/BestBuy_US/images/products/6386/6386391_sd.jpg\\', \\'brand_name\\': \\'Samsung\\', \\'upc\\': \\'887276374888\\'}, {\\'links\\': [{\\'text\\': \\'Details\\', \\'type\\': \\'pdp\\', \\'url\\': \\'https://www.amazon.com/dp/B098HQ8YRX?tag=ioniccommer00-20&linkCode=osi&th=1&psc=1\\'}], \\'merchant_name\\': \\'Amazon\\', \\'merchant_product_id\\': \\'B098HQ8YRX\\', \\'name\\': \\'Sceptre 4K IPS 27\" 3840'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['intermediate_steps'][2][0].log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check if the input is a comma-separated string of values'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['intermediate_steps'][3][0].tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_intermediate_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model = create_example_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then read in an evaluation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>context</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How much money does client 1 have in shares?</td>\n",
       "      <td>Client 1 has 20 shares. 70% of their shares ar...</td>\n",
       "      <td>Client 1 has £14,000 worth of NVDA shares (70%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much money does client 2 have in shares?</td>\n",
       "      <td>Client 2 has 10 shares. 30% of their shares ar...</td>\n",
       "      <td>Client 2 has £3,000 worth of NVDA shares (30% ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         inputs  \\\n",
       "0  How much money does client 1 have in shares?   \n",
       "1  How much money does client 2 have in shares?   \n",
       "\n",
       "                                             context  \\\n",
       "0  Client 1 has 20 shares. 70% of their shares ar...   \n",
       "1  Client 2 has 10 shares. 30% of their shares ar...   \n",
       "\n",
       "                                             targets  \n",
       "0  Client 1 has £14,000 worth of NVDA shares (70%...  \n",
       "1  Client 2 has £3,000 worth of NVDA shares (30% ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_folder_path = '\\\\'.join(os.getcwd().split('\\\\')[:-1]) +'/data/'\n",
    "file_name = 'Evaluation Dataset.csv'\n",
    "\n",
    "file_path = data_folder_path + file_name\n",
    "eval_set = pd.read_csv(file_path)\n",
    "\n",
    "display(eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate that the model works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much money does client 1 have in shares?\n",
      "\n",
      "Answer: Client 1 has £14,000 worth of NVDA shares (70% of 20 shares at £1000 per share) and £5,700 worth of APPL shares (30% of 20 shares at £190 per share). Therefore, in total, Client 1 has £19,700 in shares.\n"
     ]
    }
   ],
   "source": [
    "question = eval_set['inputs'][0]\n",
    "context = eval_set['context'][0]\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print('')\n",
    "print('Answer: ' + example_model.invoke({'inputs': question, 'context': context}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then connect to ML-Flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/30 09:25:36 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/05/30 09:25:38 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/05/30 09:25:40 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2024/05/30 09:25:40 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'toxicity' because it returned None.\n",
      "2024/05/30 09:25:40 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2024/05/30 09:25:40 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'flesch_kincaid_grade_level' because it returned None.\n",
      "2024/05/30 09:25:40 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2024/05/30 09:25:40 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'ari_grade_level' because it returned None.\n",
      "c:\\Code\\GenAIGroupProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "2024/05/30 09:25:44 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2024/05/30 09:25:44 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'toxicity' because it returned None.\n",
      "2024/05/30 09:25:44 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2024/05/30 09:25:44 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'flesch_kincaid_grade_level' because it returned None.\n",
      "2024/05/30 09:25:44 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2024/05/30 09:25:44 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'ari_grade_level' because it returned None.\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.56it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_llm(example_model, eval_set, \"openai:/gpt-3.5-turbo\", \"mlflow_development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can then take a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 742.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>context</th>\n",
       "      <th>targets</th>\n",
       "      <th>outputs</th>\n",
       "      <th>token_count</th>\n",
       "      <th>faithfulness/v1/score</th>\n",
       "      <th>faithfulness/v1/justification</th>\n",
       "      <th>answer_similarity/v1/score</th>\n",
       "      <th>answer_similarity/v1/justification</th>\n",
       "      <th>answer_correctness/v1/score</th>\n",
       "      <th>answer_correctness/v1/justification</th>\n",
       "      <th>answer_relevance/v1/score</th>\n",
       "      <th>answer_relevance/v1/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How much money does client 1 have in shares?</td>\n",
       "      <td>Client 1 has 20 shares. 70% of their shares ar...</td>\n",
       "      <td>Client 1 has £14,000 worth of NVDA shares (70%...</td>\n",
       "      <td>Client 1 has £14,000 worth of NVDA shares (70%...</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>The output correctly states the distribution o...</td>\n",
       "      <td>3</td>\n",
       "      <td>The output has moderate semantic similarity to...</td>\n",
       "      <td>5</td>\n",
       "      <td>The output is correct and demonstrates a high ...</td>\n",
       "      <td>5</td>\n",
       "      <td>The output provided directly addresses all asp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much money does client 2 have in shares?</td>\n",
       "      <td>Client 2 has 10 shares. 30% of their shares ar...</td>\n",
       "      <td>Client 2 has £3,000 worth of NVDA shares (30% ...</td>\n",
       "      <td>Client 2 has £7,300 in shares. This is calcula...</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>The output correctly calculates the amount of ...</td>\n",
       "      <td>4</td>\n",
       "      <td>The output aligns with the provided targets in...</td>\n",
       "      <td>5</td>\n",
       "      <td>The output is correct and demonstrates a high ...</td>\n",
       "      <td>5</td>\n",
       "      <td>The output directly addresses all aspects of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         inputs  \\\n",
       "0  How much money does client 1 have in shares?   \n",
       "1  How much money does client 2 have in shares?   \n",
       "\n",
       "                                             context  \\\n",
       "0  Client 1 has 20 shares. 70% of their shares ar...   \n",
       "1  Client 2 has 10 shares. 30% of their shares ar...   \n",
       "\n",
       "                                             targets  \\\n",
       "0  Client 1 has £14,000 worth of NVDA shares (70%...   \n",
       "1  Client 2 has £3,000 worth of NVDA shares (30% ...   \n",
       "\n",
       "                                             outputs  token_count  \\\n",
       "0  Client 1 has £14,000 worth of NVDA shares (70%...           66   \n",
       "1  Client 2 has £7,300 in shares. This is calcula...           76   \n",
       "\n",
       "   faithfulness/v1/score                      faithfulness/v1/justification  \\\n",
       "0                      5  The output correctly states the distribution o...   \n",
       "1                      5  The output correctly calculates the amount of ...   \n",
       "\n",
       "   answer_similarity/v1/score  \\\n",
       "0                           3   \n",
       "1                           4   \n",
       "\n",
       "                  answer_similarity/v1/justification  \\\n",
       "0  The output has moderate semantic similarity to...   \n",
       "1  The output aligns with the provided targets in...   \n",
       "\n",
       "   answer_correctness/v1/score  \\\n",
       "0                            5   \n",
       "1                            5   \n",
       "\n",
       "                 answer_correctness/v1/justification  \\\n",
       "0  The output is correct and demonstrates a high ...   \n",
       "1  The output is correct and demonstrates a high ...   \n",
       "\n",
       "   answer_relevance/v1/score  \\\n",
       "0                          5   \n",
       "1                          5   \n",
       "\n",
       "                   answer_relevance/v1/justification  \n",
       "0  The output provided directly addresses all asp...  \n",
       "1  The output directly addresses all aspects of t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(results.tables['eval_results_table'])\n",
    "display(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Client 2 has £7,300 in shares. This is calculated by taking 30% of their shares in NVDA (3 shares x £1000 = £3000) and 70% of their shares in AAPL (7 shares x £190 = £1330), then adding these two amounts together (£3000 + £1330 = £4330).'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['outputs'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the saved models using the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 58a8e7cbb25e43faa27d4a17738836e5\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002C69B59DB50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002C6F9CFA390>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {'answer_correctness/v1/mean': 5.0, 'answer_correctness/v1/p90': 5.0, 'answer_correctness/v1/variance': 0.0, 'answer_relevance/v1/mean': 5.0, 'answer_relevance/v1/p90': 5.0, 'answer_relevance/v1/variance': 0.0, 'answer_similarity/v1/mean': 3.5, 'answer_similarity/v1/p90': 3.9, 'answer_similarity/v1/variance': 0.25, 'exact_match/v1': 0.0, 'faithfulness/v1/mean': 5.0, 'faithfulness/v1/p90': 5.0, 'faithfulness/v1/variance': 0.0}\n",
      "Tags: {'mlflow.datasets': '[{\"name\":\"f4b6912a1feeee0b23e37f229253ecab\",\"hash\":\"f4b6912a1feeee0b23e37f229253ecab\",\"model\":\"d0e14892ef474e72b443a90f954ba503\"}]', 'mlflow.log-model.history': '[{\"run_id\": \"58a8e7cbb25e43faa27d4a17738836e5\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-30 08:25:21.129388\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"d0e14892ef474e72b443a90f954ba503\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1393}]', 'mlflow.loggedArtifacts': '[{\"path\": \"eval_results_table.json\", \"type\": \"table\"}]', 'mlflow.runName': 'hilarious-fly-936', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=3540, is_dir=False, path='eval_results_table.json'>, <FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: 7ff27b9287f54908a8509d29a7fd98bc\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000021137F5D610>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000021137F54690>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {'answer_correctness/v1/mean': 5.0, 'answer_correctness/v1/p90': 5.0, 'answer_correctness/v1/variance': 0.0, 'answer_relevance/v1/mean': 5.0, 'answer_relevance/v1/p90': 5.0, 'answer_relevance/v1/variance': 0.0, 'answer_similarity/v1/mean': 4.0, 'answer_similarity/v1/p90': 4.8, 'answer_similarity/v1/variance': 1.0, 'exact_match/v1': 0.0, 'faithfulness/v1/mean': 5.0, 'faithfulness/v1/p90': 5.0, 'faithfulness/v1/variance': 0.0}\n",
      "Tags: {'mlflow.datasets': '[{\"name\":\"f4b6912a1feeee0b23e37f229253ecab\",\"hash\":\"f4b6912a1feeee0b23e37f229253ecab\",\"model\":\"5f232475253f49599a820ab1c26b9575\"}]', 'mlflow.log-model.history': '[{\"run_id\": \"7ff27b9287f54908a8509d29a7fd98bc\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-30 08:20:54.366749\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"5f232475253f49599a820ab1c26b9575\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1393}]', 'mlflow.loggedArtifacts': '[{\"path\": \"eval_results_table.json\", \"type\": \"table\"}]', 'mlflow.runName': 'useful-fawn-581', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=3673, is_dir=False, path='eval_results_table.json'>, <FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: 264f06df78e9418ba85316cbd8dba4b2\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002112E7ABB10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002112E7C5AD0>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {'answer_correctness/v1/mean': 4.5, 'answer_correctness/v1/p90': 4.9, 'answer_correctness/v1/variance': 0.25, 'answer_relevance/v1/mean': 5.0, 'answer_relevance/v1/p90': 5.0, 'answer_relevance/v1/variance': 0.0, 'answer_similarity/v1/mean': 3.5, 'answer_similarity/v1/p90': 3.9, 'answer_similarity/v1/variance': 0.25, 'exact_match/v1': 0.0, 'faithfulness/v1/mean': 5.0, 'faithfulness/v1/p90': 5.0, 'faithfulness/v1/variance': 0.0}\n",
      "Tags: {'mlflow.datasets': '[{\"name\":\"f4b6912a1feeee0b23e37f229253ecab\",\"hash\":\"f4b6912a1feeee0b23e37f229253ecab\",\"model\":\"6705872e4f7141e4abf10dd3a4212e92\"}]', 'mlflow.log-model.history': '[{\"run_id\": \"264f06df78e9418ba85316cbd8dba4b2\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-29 14:59:41.045018\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"6705872e4f7141e4abf10dd3a4212e92\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1393}]', 'mlflow.loggedArtifacts': '[{\"path\": \"eval_results_table.json\", \"type\": \"table\"}]', 'mlflow.runName': 'marvelous-moose-922', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=3473, is_dir=False, path='eval_results_table.json'>, <FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: 9f33508bd7124b8c9a8e154f79c2f707\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000023F44913B10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023F6643A810>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {'answer_correctness/v1/mean': 4.5, 'answer_correctness/v1/p90': 4.9, 'answer_correctness/v1/variance': 0.25, 'answer_relevance/v1/mean': 5.0, 'answer_relevance/v1/p90': 5.0, 'answer_relevance/v1/variance': 0.0, 'answer_similarity/v1/mean': 3.5, 'answer_similarity/v1/p90': 3.9, 'answer_similarity/v1/variance': 0.25, 'exact_match/v1': 0.0, 'faithfulness/v1/mean': 5.0, 'faithfulness/v1/p90': 5.0, 'faithfulness/v1/variance': 0.0}\n",
      "Tags: {'mlflow.datasets': '[{\"name\":\"f4b6912a1feeee0b23e37f229253ecab\",\"hash\":\"f4b6912a1feeee0b23e37f229253ecab\",\"model\":\"129811ea46884d4cb26c39fe131fcdfc\"}]', 'mlflow.log-model.history': '[{\"run_id\": \"9f33508bd7124b8c9a8e154f79c2f707\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-29 14:54:30.576005\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"129811ea46884d4cb26c39fe131fcdfc\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1393}]', 'mlflow.loggedArtifacts': '[{\"path\": \"eval_results_table.json\", \"type\": \"table\"}]', 'mlflow.runName': 'tasteful-pig-749', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=3495, is_dir=False, path='eval_results_table.json'>, <FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: 60fa9c9e6a62439aa6e519cf738ea478\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001D54A7FCD10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001D54A637D10>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {}\n",
      "Tags: {'mlflow.log-model.history': '[{\"run_id\": \"60fa9c9e6a62439aa6e519cf738ea478\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-29 14:53:58.287493\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"f2080f56b138482f8f99302a929d5116\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1393}]', 'mlflow.runName': 'abundant-snail-678', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: a8ad84686c2b4606b2f20b908abdeb52\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001DCFBECBD50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001DCFBED7690>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {'answer_correctness/v1/mean': 5.0, 'answer_correctness/v1/p90': 5.0, 'answer_correctness/v1/variance': 0.0, 'answer_relevance/v1/mean': 5.0, 'answer_relevance/v1/p90': 5.0, 'answer_relevance/v1/variance': 0.0, 'answer_similarity/v1/mean': 4.0, 'answer_similarity/v1/p90': 4.0, 'answer_similarity/v1/variance': 0.0, 'exact_match/v1': 0.0, 'faithfulness/v1/mean': 5.0, 'faithfulness/v1/p90': 5.0, 'faithfulness/v1/variance': 0.0}\n",
      "Tags: {'mlflow.datasets': '[{\"name\":\"f4b6912a1feeee0b23e37f229253ecab\",\"hash\":\"f4b6912a1feeee0b23e37f229253ecab\",\"model\":\"e1f6e931e0b14b3f9967df52a87a4f0f\"}]', 'mlflow.log-model.history': '[{\"run_id\": \"a8ad84686c2b4606b2f20b908abdeb52\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-29 13:30:26.049011\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"e1f6e931e0b14b3f9967df52a87a4f0f\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1371}]', 'mlflow.loggedArtifacts': '[{\"path\": \"eval_results_table.json\", \"type\": \"table\"}]', 'mlflow.runName': 'defiant-fish-943', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=3786, is_dir=False, path='eval_results_table.json'>, <FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: 43c51047659d483381c6bf49a986df13\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000015E504CBDD0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000015E502B7210>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {}\n",
      "Tags: {'mlflow.datasets': '[{\"name\":\"a701eccb1269c49d6f3a64e53354696c\",\"hash\":\"a701eccb1269c49d6f3a64e53354696c\",\"model\":\"b2d6372e0ffe45f493876fecaa9a5cdb\"}]', 'mlflow.log-model.history': '[{\"run_id\": \"43c51047659d483381c6bf49a986df13\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-29 13:28:24.004446\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"b2d6372e0ffe45f493876fecaa9a5cdb\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1371}]', 'mlflow.runName': 'upset-jay-389', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: c01bc47da2ea43fcb5eba9e33d20bc09\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000015E504CBDD0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000015E502B7210>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {'answer_correctness/v1/mean': 5.0, 'answer_correctness/v1/p90': 5.0, 'answer_correctness/v1/variance': 0.0, 'answer_relevance/v1/mean': 5.0, 'answer_relevance/v1/p90': 5.0, 'answer_relevance/v1/variance': 0.0, 'answer_similarity/v1/mean': 3.0, 'answer_similarity/v1/p90': 3.0, 'answer_similarity/v1/variance': 0.0, 'exact_match/v1': 0.0, 'faithfulness/v1/mean': 5.0, 'faithfulness/v1/p90': 5.0, 'faithfulness/v1/variance': 0.0, 'relevance/v1/mean': 5.0, 'relevance/v1/p90': 5.0, 'relevance/v1/variance': 0.0}\n",
      "Tags: {'mlflow.datasets': '[{\"name\":\"a701eccb1269c49d6f3a64e53354696c\",\"hash\":\"a701eccb1269c49d6f3a64e53354696c\",\"model\":\"8cf2b098c50f422f947a24ca6692f338\"}]', 'mlflow.log-model.history': '[{\"run_id\": \"c01bc47da2ea43fcb5eba9e33d20bc09\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-29 13:26:41.719159\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"8cf2b098c50f422f947a24ca6692f338\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1371}]', 'mlflow.loggedArtifacts': '[{\"path\": \"eval_results_table.json\", \"type\": \"table\"}]', 'mlflow.runName': 'indecisive-skink-399', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=1997, is_dir=False, path='eval_results_table.json'>, <FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: ce173b9dfb084da6b82828507c42f335\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000015E504CBDD0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000015E502B7210>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {}\n",
      "Tags: {'mlflow.datasets': '[{\"name\":\"a701eccb1269c49d6f3a64e53354696c\",\"hash\":\"a701eccb1269c49d6f3a64e53354696c\",\"model\":\"8f6183f00ba84ca0948949757aceda0c\"}]', 'mlflow.log-model.history': '[{\"run_id\": \"ce173b9dfb084da6b82828507c42f335\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-29 13:26:16.509773\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"8f6183f00ba84ca0948949757aceda0c\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1371}]', 'mlflow.runName': 'unruly-elk-24', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n",
      "Run ID: 1e732c20df4b4f8aafdc614da6c97ab8\n",
      "Parameters: {'model': 'first=PromptTemplate(input_variables=[\\'context\\', \\'inputs\\'], template=\"You\\'re a investment manager. Using the context provided, reply to the question below to the best of your ability:\\\\nQuestion:\\\\n{inputs}\\\\nContext:\\\\n{context}\") middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000015E504CBDD0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000015E502B7210>, model_name=\\'gpt-3.5-turbo-0125\\', temperature=0.0, openai_api_key=SecretStr(\\'**********\\'), openai_proxy=\\'\\')] last=RunnableLambda(_get_content)'}\n",
      "Metrics: {}\n",
      "Tags: {'mlflow.log-model.history': '[{\"run_id\": \"1e732c20df4b4f8aafdc614da6c97ab8\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-05-29 13:25:59.820766\", \"flavors\": {\"python_function\": {\"predict_stream_fn\": \"predict_stream\", \"streamable\": true, \"model_load\": \"runnable_load\", \"model_type\": \"RunnableSequence\", \"model_data\": \"model\", \"loader_module\": \"mlflow.langchain\", \"python_version\": \"3.11.0\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"langchain\": {\"langchain_version\": \"0.2.1\", \"code\": null, \"streamable\": true, \"model_type\": \"RunnableSequence\", \"model_load\": \"runnable_load\", \"model_data\": \"model\"}}, \"model_uuid\": \"32dd228a394e4c7282ac025a03a2b502\", \"mlflow_version\": \"2.13.0\", \"model_size_bytes\": 1371}]', 'mlflow.runName': 'nebulous-doe-63', 'mlflow.source.name': 'c:\\\\Code\\\\GenAIGroupProject\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'MichaelBerney'}\n",
      "Artifacts: [<FileInfo: file_size=None, is_dir=True, path='model'>]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:8080/\")\n",
    "client = MlflowClient()\n",
    "\n",
    "experiment = client.get_experiment_by_name('mlflow_development')\n",
    "\n",
    "if experiment is None:\n",
    "    raise ValueError(f\"Experiment 'mlflow_development' not found.\")\n",
    "\n",
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id],\n",
    "                          filter_string=\"\",  # Add filter criteria if needed\n",
    "                          run_view_type=mlflow.entities.ViewType.ACTIVE_ONLY)\n",
    "\n",
    "for run in runs:\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(f\"Parameters: {run.data.params}\")\n",
    "    print(f\"Metrics: {run.data.metrics}\")\n",
    "    print(f\"Tags: {run.data.tags}\")\n",
    "    print(f\"Artifacts: {client.list_artifacts(run.info.run_id)}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_runs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Code\n",
    "\n",
    "Other code used in the development of this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.metrics.genai import answer_similarity, faithfulness, answer_correctness, answer_relevance\n",
    "# judge_model = \"openai:/gpt-3.5-turbo\"\n",
    "\n",
    "# faithfulness_metric = faithfulness(model=judge_model)\n",
    "# answer_relevance_metric = answer_relevance(model=judge_model)\n",
    "# answer_similarity_metric = answer_similarity(model=judge_model)\n",
    "# answer_correctness_metric = answer_correctness(model=judge_model)\n",
    "\n",
    "# extra_metrics = [faithfulness_metric, answer_similarity_metric, answer_correctness_metric, answer_relevance_metric]\n",
    "\n",
    "# mlflow.set_experiment('mlflow_development')\n",
    "\n",
    "# with mlflow.start_run() as run: \n",
    "#     _logged_model = mlflow.langchain.log_model(example_model, artifact_path=\"model\")\n",
    "\n",
    "#     mlflow.log_param(\"model\", example_model)\n",
    "#     results = mlflow.evaluate(_logged_model.model_uri, eval_set, model_type=\"question-answering\",\n",
    "#                                 targets=\"targets\", extra_metrics=extra_metrics,\n",
    "#                                 evaluator_config={'col_mapping': {\"inputs\": \"predictions\"}})\n",
    "\n",
    "#     mlflow.log_metrics(results.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semi working chat gpt Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.models.evaluation.base.EvaluationResult"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the model produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/30 09:25:53 WARNING mlflow.tracking.client: Not all runs have the specified table artifact. Some runs will be skipped.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'eval_results_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_results_table\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#output_df['answer'] = [d['content'] for d in output_df['outputs']]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# desired_columns = ['inputs', 'context', 'targets'] + [col for col in output_df.columns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#                                             if ('score' in col) or ('justification') in col]\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# output_df = output_df[desired_columns]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m display(output_df)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'eval_results_table'"
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame(results.tables['eval_results_table'])\n",
    "#output_df['answer'] = [d['content'] for d in output_df['outputs']]\n",
    "\n",
    "# desired_columns = ['inputs', 'context', 'targets'] + [col for col in output_df.columns\n",
    "#                                             if ('score' in col) or ('justification') in col]\n",
    "# output_df = output_df[desired_columns]\n",
    "display(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create score output func\n",
    "output_df['faithfulness/v1/score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grading prompt is:\n",
      "\n",
      "Answer Quality: If the answer given does not relate to the question, or if the question is not answered, we will give a low score. If the question is answered comprehensively we will give a higher score.\n",
      "Score 0: The question is not answered.\n",
      "Score 20: The question is barely answered, and the answer is not useful.\n",
      "Score 40: The question is barely answered in basic terms.\n",
      "Score 80: The question is barely answered correctly and accurately.\n",
      "Score 100: The question is answer perfectly, and the choices are well reasoned.\n",
      "\n",
      "EvaluationMetric(name=Answer_Quality, greater_is_better=True, long_name=Answer_Quality, version=v1, metric_details=\n",
      "Task:\n",
      "You must return the following fields in your response in two lines, one below the other:\n",
      "score: Your numerical score for the model's Answer_Quality based on the rubric\n",
      "justification: Your reasoning about the model's Answer_Quality score\n",
      "\n",
      "You are an impartial judge. You will be given an input that was sent to a machine\n",
      "learning model, and you will be given an output that the model produced. You\n",
      "may also be given additional information that was used by the model to generate the output.\n",
      "\n",
      "Your task is to determine a numerical score called Answer_Quality based on the input and output.\n",
      "A definition of Answer_Quality and a grading rubric are provided below.\n",
      "You must use the grading rubric to determine your score. You must also justify your score.\n",
      "\n",
      "Examples could be included below for reference. Make sure to use them as references and to\n",
      "understand them before completing the task.\n",
      "\n",
      "Input:\n",
      "{input}\n",
      "\n",
      "Output:\n",
      "{output}\n",
      "\n",
      "{grading_context_columns}\n",
      "\n",
      "Metric definition:\n",
      "Answer Quality is a measure of the accuracy of the answer.\n",
      "\n",
      "Grading rubric:\n",
      "Answer Quality: If the answer given does not relate to the question, or if the question is not answered, we will give a low score. If the question is answered comprehensively we will give a higher score.\n",
      "Score 0: The question is not answered.\n",
      "Score 20: The question is barely answered, and the answer is not useful.\n",
      "Score 40: The question is barely answered in basic terms.\n",
      "Score 80: The question is barely answered correctly and accurately.\n",
      "Score 100: The question is answer perfectly, and the choices are well reasoned.\n",
      "\n",
      "Examples:\n",
      "\n",
      "Example Input:\n",
      "What is the best stock that client 2 currently owns?\n",
      "\n",
      "Example Output:\n",
      "The best performing stock owned by client 2 is NVDA, which has seen a 400% increase in value in the last 10 months.\n",
      "\n",
      "Example score: 80\n",
      "Example justification: The best performing stock has been identified, and a reason is given for its choosing.\n",
      "        \n",
      "\n",
      "You must return the following fields in your response in two lines, one below the other:\n",
      "score: Your numerical score for the model's Answer_Quality based on the rubric\n",
      "justification: Your reasoning about the model's Answer_Quality score\n",
      "\n",
      "Do not add additional new lines. Do not add any other fields.\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "example = EvaluationExample(input=\"What is the best stock that client 2 currently owns?\",\n",
    "                            output=(r\"The best performing stock owned by client 2 is NVDA, which has seen a 400% \"\n",
    "                                    + \"increase in value in the last 10 months.\"),\n",
    "                            score=80,\n",
    "                            justification=(\"The best performing stock has been identified, and a reason is given for \"\n",
    "                                           + \"its choosing.\"))\n",
    "\n",
    "grading_prompt = (\"Answer Quality: If the answer given does not relate to the question, or if the question is not \"\n",
    "                  + \"answered, we will give a low score. If the question is answered comprehensively we will give a \"\n",
    "                  + \"higher score.\\nScore 0: The question is not answered.\\nScore 20: The question is barely \"\n",
    "                  + \"answered, and the answer is not useful.\\nScore 40: The question is barely answered in basic \"\n",
    "                  + \"terms.\\nScore 80: The question is barely answered correctly and accurately.\\nScore 100: The \"\n",
    "                  + \"question is answer perfectly, and the choices are well reasoned.\")\n",
    "\n",
    "# Make a metric from a Gen AI model.\n",
    "answer_quality = make_genai_metric(name=\"Answer_Quality\",\n",
    "                                   definition=(\"Answer Quality is a measure of the accuracy of the answer.\"),\n",
    "                                   model=\"openai:/gpt-3.5-turbo\",\n",
    "                                   examples=[example],\n",
    "                                   parameters={\"temperature\": 0.0},\n",
    "                                   aggregations=[\"mean\", \"variance\"],\n",
    "                                   greater_is_better=True,\n",
    "                                   grading_prompt=(grading_prompt))\n",
    "\n",
    "print('The grading prompt is:')\n",
    "print('')\n",
    "print(grading_prompt)\n",
    "print('')\n",
    "print(answer_quality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
